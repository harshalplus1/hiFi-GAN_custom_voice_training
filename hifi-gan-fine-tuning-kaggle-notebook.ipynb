{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# **HiFi-GAN Fine Tuning (Kaggle Notebook)**\n---\n<a href=\"https://github.com/jik876/hifi-gan\"> HiFi-GAN </a> | **Created by ColdFir3#9543 (Michael)**\n\nThis notebook will require: **A tacotron 2 trained model(22050hz), the dataset (same dataset and transcription file used to make the model)**\n\nThe dataset should look like this: \n\n```\nKaggle Dataset/\n          ├──wavs/\n          │    ├──1.wav\n          │    ├──2.wav\n          │    ├──3.wav\n          │    └──etc\n          └──transcription.txt\n```\n\n**You can train a tacotron 2 model <a href=\"https://www.kaggle.com/coldfir4/tacotron-2-training-kaggle-notebook\"> HERE </a>**\n\n**MAKE SURE 'GPU' HAS BEEN SELECTED AS THE ACCELERATOR IN THE NOTEBOOK SETTINGS**\n\n*UPDATED 15/10/21 VERSION 3: Added continuation for training the HiFi-GAN model*\n\n*UPDATED 22/10/21 VERSION 4: Added the ability to change batch size IF NEEDED*\n\n*UPDATED 22/10/21 VERSION 5: Fixed bugs*\n\n*UPDATED 23/10/21 VERSION 6: Fixed bugs*\n\n---\n# TRAINING INSTRUCTIONS\n* **Make sure to make your own version of this notebook for each new model**\n* **Import your dataset and your tacotron 2 model (22050hz) in the top right corner of the screen**\n* **RUN ALL**\n* **Fill in required inputs**\n* **Follow though all steps**\n---\n# CONTINUING TO TRAIN?\n* If returning back to continue training your model **MAKE SURE TO RUN ALL AND ENTER REQUIRED DATA**\n\n* Import your Model as a \"dataset\" **SEPERATELY** from the other datasets previously added\n\n* The \"dataset\" should contain the name of your character with all files within them\n\n* **DON'T MAKE ANY OF THE SETTINGS DIFFERENT FROM YOUR PREVIOUS TRAINING**\n\n* Recommended to name your \"input\" for your AI Model to be the same name as the model itself **(WILL SAVE LOTS OF TROUBLE AT STEP 3.5)**\n\n* ***(VERY IMPORTANT)*** Once your model has been trained **DO NOT FORGET TO SAVE VERSION USING 'QUICK SAVE' AS THE OPTION AND GO TO 'ADVANCED' AND CHECK 'ALWAYS SAVE OUTPUT'** so you do NOT LOSE progress\n---","metadata":{}},{"cell_type":"markdown","source":"# 1 Apply Settings via user input","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# print(\"NOT THE MODEL FILENAME ITSELF, ONLY THE NAME YOU HAD GIVEN IT WHEN IMPORTING AS DATA INTO KAGGLE\")\n# dataset_model_name = input(\"What is the name of the name you had assigned your TACOTRON2 MODEL within your KAGGLE ACCOUNT?: \")\n# model_name = input(\"What is the name of your Tacotron 2 model?: \")\n# dataset_name = input(\"What is the name of your dataset?: \")\ntranscription_name = f'/kaggle/input/tacotron-own-voice-training/metadata.csv'\n# CHARACTERNAME = input(\"What is the name of your character? (No spaces, use only '-' or '_' or '.'): \")\nBATCH_SIZE_INP = 32\n# while BATCH_SIZE_INP <= -1:\n#     BATCH_SIZE_INP = int(input(\"What batch size would you like to use (recommended: 16): \"))\n\n# while \" \" in CHARACTERNAME:\n#     CHARACTERNAME = input(\"What is the name of your character? (No spaces, use only '-' or '_' or '.'): \")\ntacotron_model = f\"/kaggle/input/tacotroncheckpoint/checkpoint_20\"\ntacotron_dataset = f\"/kaggle/input/tacotron-own-voice-training/wav/wav\"\n# train_filelist = f\"/kaggle/input/textfiles/train.txt\"\n# val_filelist = f\"/kaggle/input/textfiles/validation.txt\"\noutput_dir = f\"/kaggle/working/hifimodels/-\"\nprint(\"Settings saved\")","metadata":{"execution":{"iopub.status.busy":"2023-07-29T09:42:29.267161Z","iopub.execute_input":"2023-07-29T09:42:29.267828Z","iopub.status.idle":"2023-07-29T09:42:29.377566Z","shell.execute_reply.started":"2023-07-29T09:42:29.267734Z","shell.execute_reply":"2023-07-29T09:42:29.376637Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Settings saved\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n# 2 Download HiFi-GAN and Tacotron 2","metadata":{}},{"cell_type":"code","source":"print(\"Downloading and Intalling Tacotron 2 and HiFi-GAN...\")\n!pip install tensorflow==1.15.2\nimport os\n!git clone -q https://github.com/SortAnon/tacotron2.git\nos.chdir('/kaggle/working/tacotron2')\n!pip install inflect\n!git submodule init\n!git submodule update\n!apt-get install pv\n!apt-get install jq\n!pip install gdown\nos.chdir('/kaggle/working')\n!git clone -q https://github.com/harshalplus1/hifi-gan.git\n!pip install -q unidecode tensorboardX","metadata":{"execution":{"iopub.status.busy":"2023-07-29T09:42:48.162874Z","iopub.execute_input":"2023-07-29T09:42:48.163454Z","iopub.status.idle":"2023-07-29T09:44:22.379554Z","shell.execute_reply.started":"2023-07-29T09:42:48.163414Z","shell.execute_reply":"2023-07-29T09:44:22.378557Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading and Intalling Tacotron 2 and HiFi-GAN...\nCollecting tensorflow==1.15.2\n  Downloading tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n\u001b[K     |████████████████████████████████| 110.5 MB 68.7 MB/s eta 0:00:01\n\u001b[?25hCollecting keras-applications>=1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 4.0 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.3.0)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.12.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.32.0)\nCollecting tensorboard<1.16.0,>=1.15.0\n  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 48.4 MB/s eta 0:00:01     |████▌                           | 532 kB 48.4 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.37.0)\nRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.12.1)\nRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.15.0)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (3.18.0)\nCollecting tensorflow-estimator==1.15.1\n  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n\u001b[K     |████████████████████████████████| 503 kB 33.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.19.5)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (1.1.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15.2) (0.2.0)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (57.4.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.4)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (2.0.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.5.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.7.4.3)\nBuilding wheels for collected packages: gast\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=6909fad8148622592d26d0cf060c2df34b28bc17a3dd7dfd76dbef005abfc461\n  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\nSuccessfully built gast\nInstalling collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, astor, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.4.0\n    Uninstalling tensorflow-estimator-2.4.0:\n      Successfully uninstalled tensorflow-estimator-2.4.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Uninstalling tensorboard-2.6.0:\n      Successfully uninstalled tensorboard-2.6.0\n  Attempting uninstall: gast\n    Found existing installation: gast 0.3.3\n    Uninstalling gast-0.3.3:\n      Successfully uninstalled gast-0.3.3\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.4.1\n    Uninstalling tensorflow-2.4.1:\n      Successfully uninstalled tensorflow-2.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-probability 0.12.2 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\ntensorflow-cloud 0.1.13 requires tensorboard>=2.3.0, but you have tensorboard 1.15.0 which is incompatible.\npytorch-lightning 1.4.4 requires tensorboard>=2.2.0, but you have tensorboard 1.15.0 which is incompatible.\u001b[0m\nSuccessfully installed astor-0.8.1 gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting inflect\n  Downloading inflect-6.0.5-py3-none-any.whl (34 kB)\nCollecting pydantic<2,>=1.9.1\n  Downloading pydantic-1.10.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[K     |████████████████████████████████| 3.1 MB 12.1 MB/s eta 0:00:01\n\u001b[?25hCollecting typing-extensions>=4.2.0\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nInstalling collected packages: typing-extensions, pydantic, inflect\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4.3\n    Uninstalling typing-extensions-3.7.4.3:\n      Successfully uninstalled typing-extensions-3.7.4.3\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.8.2\n    Uninstalling pydantic-1.8.2:\n      Successfully uninstalled pydantic-1.8.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 21.8.3 requires cupy-cuda110, which is not installed.\npytorch-lightning 1.4.4 requires tensorboard>=2.2.0, but you have tensorboard 1.15.0 which is incompatible.\narviz 0.11.2 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.7.1 which is incompatible.\naiobotocore 1.4.1 requires botocore<1.20.107,>=1.20.106, but you have botocore 1.21.44 which is incompatible.\u001b[0m\nSuccessfully installed inflect-6.0.5 pydantic-1.10.12 typing-extensions-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nSubmodule 'waveglow' (https://github.com/NVIDIA/waveglow) registered for path 'waveglow'\nCloning into '/kaggle/working/tacotron2/waveglow'...\nSubmodule path 'waveglow': checked out '5bc2a53e20b3b533362f974cfa1ea0267ae1c2b1'\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nSuggested packages:\n  doc-base\nThe following NEW packages will be installed:\n  pv\n0 upgraded, 1 newly installed, 0 to remove and 22 not upgraded.\nNeed to get 48.3 kB of archives.\nAfter this operation, 123 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 pv amd64 1.6.6-1 [48.3 kB]\nFetched 48.3 kB in 1s (87.0 kB/s)\ndebconf: delaying package configuration, since apt-utils is not installed\nSelecting previously unselected package pv.\n(Reading database ... 112324 files and directories currently installed.)\nPreparing to unpack .../archives/pv_1.6.6-1_amd64.deb ...\nUnpacking pv (1.6.6-1) ...\nSetting up pv (1.6.6-1) ...\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\njq is already the newest version (1.5+dfsg-2).\n0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\nCollecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.0.12)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.62.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.10.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.25.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.2.1)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2021.5.30)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.6)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (4.0.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n# 3 Assign batch size and generate ground truth-aligned spectrograms. This will help HiFi-GAN learn what your Tacotron model sounds like","metadata":{}},{"cell_type":"code","source":"!apt-get update\n!apt-get install sox -y","metadata":{"execution":{"iopub.status.busy":"2023-07-29T09:44:27.953675Z","iopub.execute_input":"2023-07-29T09:44:27.953981Z","iopub.status.idle":"2023-07-29T09:44:40.147514Z","shell.execute_reply.started":"2023-07-29T09:44:27.953948Z","shell.execute_reply":"2023-07-29T09:44:40.146546Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Get:1 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease [5004 B]\nIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\nGet:3 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease [6396 B] \nGet:4 http://packages.cloud.google.com/apt cloud-sdk InRelease [6361 B]        \nIgn:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\nErr:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n  Certificate verification failed: The certificate is NOT trusted. The certificate issuer is unknown.  Could not handshake: Error in the certificate verification. [IP: 152.195.19.142 443]\nErr:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n  Certificate verification failed: The certificate is NOT trusted. The certificate issuer is unknown.  Could not handshake: Error in the certificate verification. [IP: 152.195.19.142 443]\nErr:1 http://packages.cloud.google.com/apt gcsfuse-bionic InRelease            \n  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\nGet:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]    \nHit:9 http://archive.ubuntu.com/ubuntu bionic InRelease                        \nErr:3 http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease          \n  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\nGet:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]     \nErr:4 http://packages.cloud.google.com/apt cloud-sdk InRelease                 \n  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\nGet:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]   \nGet:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1636 kB]\nGet:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3785 kB]\nGet:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3373 kB]\nGet:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [30.8 kB]\nGet:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2410 kB]\nGet:17 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [23.8 kB]\nGet:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1688 kB]\nGet:19 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1728 kB]\nGet:20 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [20.6 kB]\nGet:21 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [64.0 kB]\nReading package lists... Done                          \nW: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/InRelease: No system certificates available. Try installing ca-certificates.\nW: https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/InRelease: No system certificates available. Try installing ca-certificates.\nW: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/Release: No system certificates available. Try installing ca-certificates.\nE: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release' no longer has a Release file.\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\nW: https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/Release: No system certificates available. Try installing ca-certificates.\nE: The repository 'https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release' no longer has a Release file.\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://packages.cloud.google.com/apt gcsfuse-bionic InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://packages.cloud.google.com/apt cloud-sdk-bionic InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\nW: An error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://packages.cloud.google.com/apt cloud-sdk InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY B53DC80D13EDEF05\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base\n  libsox3\nSuggested packages:\n  libsox-fmt-all\nThe following NEW packages will be installed:\n  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base\n  libsox3 sox\n0 upgraded, 6 newly installed, 0 to remove and 191 not upgraded.\nNeed to get 507 kB of archives.\nAfter this operation, 1507 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrnb0 amd64 0.1.3-2.1 [92.0 kB]\nGet:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopencore-amrwb0 amd64 0.1.3-2.1 [45.8 kB]\nGet:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox3 amd64 14.4.2-3ubuntu0.18.04.3 [226 kB]\nGet:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2-3ubuntu0.18.04.3 [10.6 kB]\nGet:5 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libsox-fmt-base amd64 14.4.2-3ubuntu0.18.04.3 [32.1 kB]\nGet:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 sox amd64 14.4.2-3ubuntu0.18.04.3 [101 kB]\nFetched 507 kB in 1s (428 kB/s)\ndebconf: delaying package configuration, since apt-utils is not installed\nSelecting previously unselected package libopencore-amrnb0:amd64.\n(Reading database ... 112336 files and directories currently installed.)\nPreparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\nUnpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\nSelecting previously unselected package libopencore-amrwb0:amd64.\nPreparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\nUnpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\nSelecting previously unselected package libsox3:amd64.\nPreparing to unpack .../2-libsox3_14.4.2-3ubuntu0.18.04.3_amd64.deb ...\nUnpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.3) ...\nSelecting previously unselected package libsox-fmt-alsa:amd64.\nPreparing to unpack .../3-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.3_amd64.deb ...\nUnpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.3) ...\nSelecting previously unselected package libsox-fmt-base:amd64.\nPreparing to unpack .../4-libsox-fmt-base_14.4.2-3ubuntu0.18.04.3_amd64.deb ...\nUnpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.3) ...\nSelecting previously unselected package sox.\nPreparing to unpack .../5-sox_14.4.2-3ubuntu0.18.04.3_amd64.deb ...\nUnpacking sox (14.4.2-3ubuntu0.18.04.3) ...\nSetting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\nSetting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\nSetting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.3) ...\nSetting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.3) ...\nSetting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.3) ...\nSetting up sox (14.4.2-3ubuntu0.18.04.3) ...\nProcessing triggers for libc-bin (2.27-3ubuntu1.4) ...\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvcuvid.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-rtcore.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-glvkspirv.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opticalflow.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opticalflow.so is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libGLESv1_CM_nvidia.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libEGL_nvidia.so.0 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fbc.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libEGL_nvidia.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libGLESv2_nvidia.so.2 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opticalflow.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libcuda.so is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ifr.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-encode.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libGLX_nvidia.so.0 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-allocator.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvcuvid.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cbl.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-tls.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-glsi.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libGLESv2_nvidia.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvoptix.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ngx.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libGLESv1_CM_nvidia.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-encode.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ifr.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-fbc.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ngx.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-allocator.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libGLX_nvidia.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvoptix.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-glcore.so.450.119.04 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-cfg.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libvdpau_nvidia.so.1 is empty, not checked.\n/sbin/ldconfig.real: File /usr/lib/x86_64-linux-gnu/libnvidia-eglcore.so.450.119.04 is empty, not checked.\nProcessing triggers for mime-support (3.60ubuntu1) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!soxi /kaggle/input/tacotron-own-voice-training/wav/wav/000.wav\n","metadata":{"execution":{"iopub.status.busy":"2023-07-29T09:44:51.551911Z","iopub.execute_input":"2023-07-29T09:44:51.552268Z","iopub.status.idle":"2023-07-29T09:44:52.598360Z","shell.execute_reply.started":"2023-07-29T09:44:51.552216Z","shell.execute_reply":"2023-07-29T09:44:52.597387Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\nInput File     : '/kaggle/input/tacotron-own-voice-training/wav/wav/000.wav'\nChannels       : 1\nSample Rate    : 32000\nPrecision      : 16-bit\nDuration       : 00:00:01.54 = 49392 samples ~ 115.763 CDDA sectors\nFile Size      : 98.8k\nBit Rate       : 512k\nSample Encoding: 16-bit Signed Integer PCM\n\n","output_type":"stream"}]},{"cell_type":"code","source":"cd tacotron2","metadata":{"execution":{"iopub.status.busy":"2023-07-29T09:45:11.212186Z","iopub.execute_input":"2023-07-29T09:45:11.212544Z","iopub.status.idle":"2023-07-29T09:45:11.219651Z","shell.execute_reply.started":"2023-07-29T09:45:11.212514Z","shell.execute_reply":"2023-07-29T09:45:11.218829Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/working/tacotron2\n","output_type":"stream"}]},{"cell_type":"code","source":"mkdir wav","metadata":{"execution":{"iopub.status.busy":"2023-07-29T09:45:12.475187Z","iopub.execute_input":"2023-07-29T09:45:12.475535Z","iopub.status.idle":"2023-07-29T09:45:13.470457Z","shell.execute_reply.started":"2023-07-29T09:45:12.475499Z","shell.execute_reply":"2023-07-29T09:45:13.469336Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import os\nfor file in os.listdir('/kaggle/input/tacotron-own-voice-training/wav/wav/'):\n     if file.endswith(\".wav\"):\n        path1='/kaggle/input/tacotron-own-voice-training/wav/wav/'+file\n        path2='/kaggle/working/tacotron2/wav/'+file\n        !sox $path1 -r 22050 -c 1 $path2","metadata":{"execution":{"iopub.status.busy":"2023-07-29T09:45:17.089771Z","iopub.execute_input":"2023-07-29T09:45:17.090094Z","iopub.status.idle":"2023-07-29T10:02:03.821529Z","shell.execute_reply.started":"2023-07-29T09:45:17.090057Z","shell.execute_reply":"2023-07-29T10:02:03.820451Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"sox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 2 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 2 samples; decrease volume?\nsox WARN dither: dither clipped 2 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 2 samples; decrease volume?\nsox WARN dither: dither clipped 2 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 2 samples; decrease volume?\nsox WARN dither: dither clipped 2 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 2 samples; decrease volume?\nsox WARN dither: dither clipped 2 samples; decrease volume?\nsox WARN rate: rate clipped 2 samples; decrease volume?\nsox WARN dither: dither clipped 2 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 2 samples; decrease volume?\nsox WARN dither: dither clipped 2 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 2 samples; decrease volume?\nsox WARN dither: dither clipped 2 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\nsox WARN rate: rate clipped 1 samples; decrease volume?\nsox WARN dither: dither clipped 1 samples; decrease volume?\n","output_type":"stream"}]},{"cell_type":"code","source":"!soxi /kaggle/working/tacotron2/wav/000.wav","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:03:20.967526Z","iopub.execute_input":"2023-07-29T10:03:20.967867Z","iopub.status.idle":"2023-07-29T10:03:21.990463Z","shell.execute_reply.started":"2023-07-29T10:03:20.967833Z","shell.execute_reply":"2023-07-29T10:03:21.989385Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\nInput File     : '/kaggle/working/tacotron2/wav/000.wav'\nChannels       : 1\nSample Rate    : 22050\nPrecision      : 16-bit\nDuration       : 00:00:01.54 = 34034 samples ~ 115.762 CDDA sectors\nFile Size      : 68.1k\nBit Rate       : 353k\nSample Encoding: 16-bit Signed Integer PCM\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\n\nos.chdir(\"/kaggle/working/hifi-gan\")\n\nwith open('config_v1b.json') as f:\n  json_config = json.load(f)\n  json_config[\"batch_size\"] = BATCH_SIZE_INP\n\nwith open('config_v1b.json', 'w') as JSON_FILE:\n  json.dump(json_config, JSON_FILE)","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:03:29.630814Z","iopub.execute_input":"2023-07-29T10:03:29.631153Z","iopub.status.idle":"2023-07-29T10:03:29.638356Z","shell.execute_reply.started":"2023-07-29T10:03:29.631115Z","shell.execute_reply":"2023-07-29T10:03:29.637565Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nmetadata = pd.read_csv(\"/kaggle/input/tacotron-own-voice-training/metadata.csv\")\n\ntotal = len(metadata)\nsplit = 0.85\ntrain = int(total * split)\n\ntrain_metadata = metadata[:train]\nval_metadata = metadata[train:]\n\nwith open('/kaggle/working/tacotron2/filelists/ljs_audio_text_train_filelist.txt', 'w') as f:\n    for _, (index, text, _) in train_metadata.iterrows():\n        filepath = '/kaggle/working/tacotron2/wav/%03d.wav' % index\n        f.write(filepath + '|' + text + '\\n')\n\nwith open('/kaggle/working/tacotron2/filelists/ljs_audio_text_test_filelist.txt', 'w') as f:\n    for _, (index, text, _) in val_metadata.iterrows():\n        filepath = '/kaggle/working/tacotron2/wav/%03d.wav' % index\n        f.write(filepath + '|' + text + '\\n')\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:03:40.735731Z","iopub.execute_input":"2023-07-29T10:03:40.736523Z","iopub.status.idle":"2023-07-29T10:03:40.848778Z","shell.execute_reply.started":"2023-07-29T10:03:40.736488Z","shell.execute_reply":"2023-07-29T10:03:40.847970Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/tacotron2/filelists/ljs_audio_text_train_filelist.txt') as f:\n    taco_filelist = f.readlines()\nwith open('/kaggle/working/tacotron2/filelists/ljs_audio_text_test_filelist.txt') as f:\n     taco_filelist.extend(f.readlines())","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:03:43.682320Z","iopub.execute_input":"2023-07-29T10:03:43.682731Z","iopub.status.idle":"2023-07-29T10:03:43.689550Z","shell.execute_reply.started":"2023-07-29T10:03:43.682696Z","shell.execute_reply":"2023-07-29T10:03:43.688755Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nos.chdir('/kaggle/working/tacotron2')\nif os.path.exists(\"/kaggle/working/tacotron2/wavs\"):\n    shutil.rmtree(\"/kaggle/working/tacotron2/wavs\")\nos.mkdir(\"wavs\")\nos.chdir(\"wavs\")\n    \n# os.system(f'cp -a /kaggle/input/tacotron-own-voice-training/wav ../')\n    \nif os.path.exists(\"/kaggle/working/tacotron2/wavs/wavs\"):\n    shutil.move(\"/kaggle/working/tacotron2/wavs/wavs\", \"/kaggle/working/tacotron2/tempwavs\")\n    shutil.rmtree(\"/kaggle/working/tacotron2/wavs\")\n    shutil.move(\"/kaggle/working/tacotron2/tempwavs\", \"/kaggle/working/tacotron2/wavs\")\n\nos.chdir('/kaggle/working/tacotron2')\nshutil.copyfile(tacotron_model, \"/kaggle/working/tacotron2/tacomodel\")\nseen_files = []\nwith open(\"/kaggle/working/tacotron2/filelists/ljs_audio_text_train_filelist.txt\", \"w\") as f:\n    for x in taco_filelist:\n        if x.split(\"|\")[0] not in seen_files:\n            seen_files.append(x.split(\"|\")[0])\n            f.write(x)\nif os.path.exists(\"/kaggle/working/tacotron2/GTAOutput\"):\n    shutil.rmtree(\"/kaggle/working/tacotron2/GTAOutput\")\nos.mkdir(\"GTAOutput\")\n!python GTA.py -c tacomodel -o GTAOutput","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:04:11.283340Z","iopub.execute_input":"2023-07-29T10:04:11.283629Z","iopub.status.idle":"2023-07-29T10:11:27.761260Z","shell.execute_reply.started":"2023-07-29T10:04:11.283600Z","shell.execute_reply":"2023-07-29T10:11:27.760262Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"FP16 Run: False\nDynamic Loss Scaling: True\nDistributed Run: False\ncuDNN Enabled: True\ncuDNN Benchmark: False\nWarm starting model from checkpoint 'tacomodel'\n100%|███████████████████████████████████████| 1000/1000 [06:49<00:00,  2.44it/s]\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n# **(CONTINUING TO TRAIN?)** 3.5 Transfer Model into the working directory","metadata":{}},{"cell_type":"code","source":"CONTINUEQ = input(\"Are you continuing to train your model? [Y/N]: \").upper()\nwhile CONTINUEQ not in (\"Y\",\"N\"):\n    CONTINUEQ = input(\"Please only enter Y or N\\nAre you continuing to train your model? [Y/N]: \")\n\nif CONTINUEQ == \"Y\":\n    os.makedirs(f'../hifimodels/{CHARACTERNAME}')\n    print(\"NOT THE MODEL FILENAME ITSELF, ONLY THE NAME YOU HAD GIVEN IT WHEN IMPORTING AS DATA INTO KAGGLE\")\n    MODELDATA_FILENAME = input(\"What is the name of the name you had assigned your HiFi-GAN model folder within your KAGGLE ACCOUNT?: \")\n    os.system(f'cp -a ../../input/{MODELDATA_FILENAME}/{CHARACTERNAME} ../hifimodels/')\nelse:\n    print(\"Ok\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n# 4 Train HiFI-GAN for 5000+ steps (recommended) but if your tacotron 2 model sounds a little too rough you should train \nStop the cell to finish the training","metadata":{}},{"cell_type":"code","source":"f = open('/kaggle/working/tacotron2/filelists/ljs_audio_text_train_filelist.txt', 'r')\ncontent = f. read()\nwith open('training_file.txt', 'w') as f:\n    f.write(content[:64499])","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:17:12.465680Z","iopub.execute_input":"2023-07-29T10:17:12.466038Z","iopub.status.idle":"2023-07-29T10:17:12.473297Z","shell.execute_reply.started":"2023-07-29T10:17:12.466001Z","shell.execute_reply":"2023-07-29T10:17:12.472311Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"f = open('/kaggle/working/tacotron2/filelists/ljs_audio_text_train_filelist.txt', 'r')\ncontent = f. read()\nwith open('validation_file.txt', 'w') as f:\n    f.write(content[64499:])","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:17:12.795122Z","iopub.execute_input":"2023-07-29T10:17:12.795948Z","iopub.status.idle":"2023-07-29T10:17:12.801698Z","shell.execute_reply.started":"2023-07-29T10:17:12.795908Z","shell.execute_reply":"2023-07-29T10:17:12.800930Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_filelist = f'/kaggle/working/tacotron2/training_file.txt'\nval_filelist = f'/kaggle/working/tacotron2/validation_file.txt'","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:17:54.177461Z","iopub.execute_input":"2023-07-29T10:17:54.178284Z","iopub.status.idle":"2023-07-29T10:17:54.182747Z","shell.execute_reply.started":"2023-07-29T10:17:54.178221Z","shell.execute_reply":"2023-07-29T10:17:54.181985Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"checkpoint_interval = 250\n\nd = 'https://drive.google.com/uc?id='\n\nos.chdir(\"/kaggle/working/hifi-gan\")\nif os.path.exists(\"/kaggle/working/hifi-gan/ft_dataset\"):\n    shutil.rmtree(\"/kaggle/working/hifi-gan/ft_dataset\")\nshutil.copytree(\"/kaggle/working/tacotron2/GTAOutput/mels/\", \"/kaggle/working/hifi-gan/ft_dataset/wavs/\")\nif os.path.exists(\"/kaggle/working/hifi-gan/wavs\"):\n    shutil.rmtree(\"/kaggle/working/hifi-gan/wavs\")\nshutil.copytree(\"/kaggle/working/tacotron2/wav/\", \"/kaggle/working/hifi-gan/wavs/\")\nshutil.copyfile(train_filelist, \"/kaggle/working/hifi-gan/training.txt\")\nshutil.copyfile(val_filelist, \"/kaggle/working/hifi-gan/validation.txt\")\n\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\nif not os.path.exists(os.path.join(output_dir, \"do_00000000\")):\n    print(\"Downloading universal model...\")\n    os.system(f\"gdown {d}1O63eHZR9t1haCdRHQcEgMfMNxiOciSru -O {os.path.join(output_dir, 'do_00000000')}\")\n    os.system(f\"gdown {d}1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW -O {os.path.join(output_dir, 'g_00000000')}\")\n    start_from_universal = \"--warm_start True \"\nelse:\n    start_from_universal = \"\"\n\n!python train.py --fine_tuning True --config config_v1b.json \\\n{start_from_universal}\\\n--checkpoint_interval {checkpoint_interval} --checkpoint_path \"{output_dir}\" \\\n--input_training_file \"/kaggle/working/hifi-gan/training.txt\" \\\n--input_validation_file \"/kaggle/working/hifi-gan/validation.txt\" \\\n--input_wavs_dir \"\" --input_mels_dir \"ft_dataset\"","metadata":{"execution":{"iopub.status.busy":"2023-07-29T10:18:01.709156Z","iopub.execute_input":"2023-07-29T10:18:01.710017Z","iopub.status.idle":"2023-07-29T11:24:55.284271Z","shell.execute_reply.started":"2023-07-29T10:18:01.709966Z","shell.execute_reply":"2023-07-29T11:24:55.283301Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Downloading universal model...\n","output_type":"stream"},{"name":"stderr","text":"Downloading...\nFrom (uriginal): https://drive.google.com/uc?id=1O63eHZR9t1haCdRHQcEgMfMNxiOciSru\nFrom (redirected): https://drive.google.com/uc?id=1O63eHZR9t1haCdRHQcEgMfMNxiOciSru&confirm=t&uuid=71358c20-4274-49e9-a479-cbbed114e0b0\nTo: /kaggle/working/hifimodels/-/do_00000000\n100%|██████████| 960M/960M [00:10<00:00, 89.9MB/s] \nDownloading...\nFrom: https://drive.google.com/uc?id=1qpgI41wNXFcH-iKq1Y42JlBC9j0je8PW\nTo: /kaggle/working/hifimodels/-/g_00000000\n100%|██████████| 55.8M/55.8M [00:01<00:00, 46.7MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Initializing Training Process..\nBatch size per GPU : 32\nGenerator(\n  (conv_pre): Conv1d(80, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n  (ups): ModuleList(\n    (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(8,), padding=(4,))\n    (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(8,), padding=(4,))\n    (2): ConvTranspose1d(128, 64, kernel_size=(4,), stride=(2,), padding=(1,))\n    (3): ConvTranspose1d(64, 32, kernel_size=(4,), stride=(2,), padding=(1,))\n  )\n  (resblocks): ModuleList(\n    (0): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n      )\n    )\n    (1): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n        (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n        (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n        (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n      )\n    )\n    (2): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n        (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n        (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n        (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n      )\n    )\n    (3): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n        (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n        (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n      )\n    )\n    (4): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n        (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n        (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n        (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n      )\n    )\n    (5): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n        (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n        (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n        (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n      )\n    )\n    (6): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n        (1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n        (2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n      )\n    )\n    (7): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n        (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n        (1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n        (2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n      )\n    )\n    (8): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n        (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n        (1): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n        (2): Conv1d(64, 64, kernel_size=(11,), stride=(1,), padding=(5,))\n      )\n    )\n    (9): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n        (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n        (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n        (1): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n        (2): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n      )\n    )\n    (10): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n        (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n        (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n        (1): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n        (2): Conv1d(32, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n      )\n    )\n    (11): ResBlock1(\n      (convs1): ModuleList(\n        (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n        (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n      )\n      (convs2): ModuleList(\n        (0): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n        (1): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n        (2): Conv1d(32, 32, kernel_size=(11,), stride=(1,), padding=(5,))\n      )\n    )\n  )\n  (conv_post): Conv1d(32, 1, kernel_size=(7,), stride=(1,), padding=(3,))\n)\ncheckpoints directory :  /kaggle/working/hifimodels/-\nLoading '/kaggle/working/hifimodels/-/g_00000000'\nComplete.\nLoading '/kaggle/working/hifimodels/-/do_00000000'\nComplete.\nCurrent learning rate: 2.91e-05\nEpoch: 1\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n  normalized, onesided, return_complex)\nSteps : 5, Gen Loss Total : 41.883, Mel-Spec. Error : 0.609, s/b : 2.362\nSteps : 10, Gen Loss Total : 42.052, Mel-Spec. Error : 0.600, s/b : 2.364\nSteps : 15, Gen Loss Total : 39.538, Mel-Spec. Error : 0.560, s/b : 2.352\nSteps : 20, Gen Loss Total : 40.782, Mel-Spec. Error : 0.573, s/b : 2.361\nTime taken for epoch 1 is 58 sec\n\nCurrent learning rate: 2.8227e-05\nEpoch: 2\nSteps : 25, Gen Loss Total : 42.760, Mel-Spec. Error : 0.588, s/b : 2.354\nSteps : 30, Gen Loss Total : 40.019, Mel-Spec. Error : 0.555, s/b : 2.391\nSteps : 35, Gen Loss Total : 39.674, Mel-Spec. Error : 0.560, s/b : 2.349\nSteps : 40, Gen Loss Total : 43.067, Mel-Spec. Error : 0.608, s/b : 2.357\nTime taken for epoch 2 is 50 sec\n\nCurrent learning rate: 2.738019e-05\nEpoch: 3\nSteps : 45, Gen Loss Total : 37.240, Mel-Spec. Error : 0.509, s/b : 2.358\nSteps : 50, Gen Loss Total : 39.531, Mel-Spec. Error : 0.544, s/b : 2.364\nSteps : 55, Gen Loss Total : 38.767, Mel-Spec. Error : 0.534, s/b : 2.366\nSteps : 60, Gen Loss Total : 38.662, Mel-Spec. Error : 0.526, s/b : 2.350\nTime taken for epoch 3 is 50 sec\n\nCurrent learning rate: 2.6558784299999998e-05\nEpoch: 4\nSteps : 65, Gen Loss Total : 40.767, Mel-Spec. Error : 0.549, s/b : 2.360\nSteps : 70, Gen Loss Total : 40.868, Mel-Spec. Error : 0.550, s/b : 2.375\nSteps : 75, Gen Loss Total : 40.979, Mel-Spec. Error : 0.549, s/b : 2.367\nSteps : 80, Gen Loss Total : 40.818, Mel-Spec. Error : 0.542, s/b : 2.356\nTime taken for epoch 4 is 50 sec\n\nCurrent learning rate: 2.5762020770999997e-05\nEpoch: 5\nSteps : 85, Gen Loss Total : 41.135, Mel-Spec. Error : 0.564, s/b : 2.456\nSteps : 90, Gen Loss Total : 42.004, Mel-Spec. Error : 0.569, s/b : 2.372\nSteps : 95, Gen Loss Total : 39.484, Mel-Spec. Error : 0.548, s/b : 2.357\nSteps : 100, Gen Loss Total : 39.672, Mel-Spec. Error : 0.530, s/b : 2.355\nSteps : 105, Gen Loss Total : 40.005, Mel-Spec. Error : 0.540, s/b : 2.354\nTime taken for epoch 5 is 50 sec\n\nCurrent learning rate: 2.4989160147869996e-05\nEpoch: 6\nSteps : 110, Gen Loss Total : 40.028, Mel-Spec. Error : 0.545, s/b : 2.359\nSteps : 115, Gen Loss Total : 39.724, Mel-Spec. Error : 0.531, s/b : 2.359\nSteps : 120, Gen Loss Total : 38.350, Mel-Spec. Error : 0.510, s/b : 2.356\nSteps : 125, Gen Loss Total : 39.018, Mel-Spec. Error : 0.534, s/b : 2.361\nTime taken for epoch 6 is 50 sec\n\nCurrent learning rate: 2.4239485343433896e-05\nEpoch: 7\nSteps : 130, Gen Loss Total : 38.979, Mel-Spec. Error : 0.535, s/b : 2.361\nSteps : 135, Gen Loss Total : 38.760, Mel-Spec. Error : 0.537, s/b : 2.370\nSteps : 140, Gen Loss Total : 39.766, Mel-Spec. Error : 0.561, s/b : 2.357\nSteps : 145, Gen Loss Total : 38.142, Mel-Spec. Error : 0.528, s/b : 2.354\nTime taken for epoch 7 is 50 sec\n\nCurrent learning rate: 2.351230078313088e-05\nEpoch: 8\nSteps : 150, Gen Loss Total : 38.102, Mel-Spec. Error : 0.511, s/b : 2.367\nSteps : 155, Gen Loss Total : 39.118, Mel-Spec. Error : 0.524, s/b : 2.365\nSteps : 160, Gen Loss Total : 38.611, Mel-Spec. Error : 0.523, s/b : 2.370\nSteps : 165, Gen Loss Total : 39.518, Mel-Spec. Error : 0.548, s/b : 2.351\nTime taken for epoch 8 is 50 sec\n\nCurrent learning rate: 2.2806931759636953e-05\nEpoch: 9\nSteps : 170, Gen Loss Total : 38.924, Mel-Spec. Error : 0.521, s/b : 2.364\nSteps : 175, Gen Loss Total : 40.389, Mel-Spec. Error : 0.542, s/b : 2.368\nSteps : 180, Gen Loss Total : 38.895, Mel-Spec. Error : 0.513, s/b : 2.367\nSteps : 185, Gen Loss Total : 36.848, Mel-Spec. Error : 0.495, s/b : 2.359\nTime taken for epoch 9 is 50 sec\n\nCurrent learning rate: 2.2122723806847845e-05\nEpoch: 10\nSteps : 190, Gen Loss Total : 39.138, Mel-Spec. Error : 0.534, s/b : 2.452\nSteps : 195, Gen Loss Total : 39.401, Mel-Spec. Error : 0.523, s/b : 2.359\nSteps : 200, Gen Loss Total : 35.870, Mel-Spec. Error : 0.488, s/b : 2.367\nSteps : 205, Gen Loss Total : 38.489, Mel-Spec. Error : 0.514, s/b : 2.360\nSteps : 210, Gen Loss Total : 37.934, Mel-Spec. Error : 0.501, s/b : 2.355\nTime taken for epoch 10 is 50 sec\n\nCurrent learning rate: 2.145904209264241e-05\nEpoch: 11\nSteps : 215, Gen Loss Total : 38.167, Mel-Spec. Error : 0.509, s/b : 2.393\nSteps : 220, Gen Loss Total : 38.577, Mel-Spec. Error : 0.515, s/b : 2.360\nSteps : 225, Gen Loss Total : 37.490, Mel-Spec. Error : 0.510, s/b : 2.353\nSteps : 230, Gen Loss Total : 36.396, Mel-Spec. Error : 0.485, s/b : 2.368\nTime taken for epoch 11 is 50 sec\n\nCurrent learning rate: 2.0815270829863137e-05\nEpoch: 12\nSteps : 235, Gen Loss Total : 37.846, Mel-Spec. Error : 0.511, s/b : 2.372\nSteps : 240, Gen Loss Total : 38.902, Mel-Spec. Error : 0.532, s/b : 2.370\nSteps : 245, Gen Loss Total : 38.323, Mel-Spec. Error : 0.523, s/b : 2.354\nSteps : 250, Gen Loss Total : 37.605, Mel-Spec. Error : 0.497, s/b : 2.352\nSaving checkpoint to /kaggle/working/hifimodels/-/g_00000000\nComplete.\nSaving checkpoint to /kaggle/working/hifimodels/-/do_00000000\nComplete.\nTime taken for epoch 12 is 53 sec\n\nCurrent learning rate: 2.0190812704967242e-05\nEpoch: 13\nSteps : 255, Gen Loss Total : 39.180, Mel-Spec. Error : 0.508, s/b : 2.372\nSteps : 260, Gen Loss Total : 38.075, Mel-Spec. Error : 0.500, s/b : 2.361\nSteps : 265, Gen Loss Total : 37.146, Mel-Spec. Error : 0.487, s/b : 2.358\nSteps : 270, Gen Loss Total : 38.095, Mel-Spec. Error : 0.509, s/b : 2.354\nTime taken for epoch 13 is 50 sec\n\nCurrent learning rate: 1.9585088323818226e-05\nEpoch: 14\nSteps : 275, Gen Loss Total : 39.343, Mel-Spec. Error : 0.508, s/b : 2.360\nSteps : 280, Gen Loss Total : 37.929, Mel-Spec. Error : 0.496, s/b : 2.373\nSteps : 285, Gen Loss Total : 37.300, Mel-Spec. Error : 0.495, s/b : 2.363\nSteps : 290, Gen Loss Total : 39.294, Mel-Spec. Error : 0.523, s/b : 2.362\nTime taken for epoch 14 is 50 sec\n\nCurrent learning rate: 1.8997535674103678e-05\nEpoch: 15\nSteps : 295, Gen Loss Total : 37.835, Mel-Spec. Error : 0.504, s/b : 2.478\nSteps : 300, Gen Loss Total : 37.439, Mel-Spec. Error : 0.499, s/b : 2.363\nSteps : 305, Gen Loss Total : 36.792, Mel-Spec. Error : 0.500, s/b : 2.353\nSteps : 310, Gen Loss Total : 36.968, Mel-Spec. Error : 0.489, s/b : 2.353\nSteps : 315, Gen Loss Total : 37.698, Mel-Spec. Error : 0.505, s/b : 2.355\nTime taken for epoch 15 is 50 sec\n\nCurrent learning rate: 1.8427609603880567e-05\nEpoch: 16\nSteps : 320, Gen Loss Total : 36.559, Mel-Spec. Error : 0.488, s/b : 2.390\nSteps : 325, Gen Loss Total : 37.639, Mel-Spec. Error : 0.501, s/b : 2.372\nSteps : 330, Gen Loss Total : 38.648, Mel-Spec. Error : 0.499, s/b : 2.358\nSteps : 335, Gen Loss Total : 37.291, Mel-Spec. Error : 0.503, s/b : 2.369\nTime taken for epoch 16 is 50 sec\n\nCurrent learning rate: 1.787478131576415e-05\nEpoch: 17\nSteps : 340, Gen Loss Total : 38.254, Mel-Spec. Error : 0.511, s/b : 2.370\nSteps : 345, Gen Loss Total : 38.768, Mel-Spec. Error : 0.514, s/b : 2.366\nSteps : 350, Gen Loss Total : 36.587, Mel-Spec. Error : 0.492, s/b : 2.352\nSteps : 355, Gen Loss Total : 37.712, Mel-Spec. Error : 0.515, s/b : 2.353\nTime taken for epoch 17 is 50 sec\n\nCurrent learning rate: 1.7338537876291225e-05\nEpoch: 18\nSteps : 360, Gen Loss Total : 38.207, Mel-Spec. Error : 0.513, s/b : 2.359\nSteps : 365, Gen Loss Total : 36.704, Mel-Spec. Error : 0.491, s/b : 2.364\nSteps : 370, Gen Loss Total : 36.077, Mel-Spec. Error : 0.491, s/b : 2.365\nSteps : 375, Gen Loss Total : 37.142, Mel-Spec. Error : 0.505, s/b : 2.361\nTime taken for epoch 18 is 50 sec\n\nCurrent learning rate: 1.6818381740002487e-05\nEpoch: 19\nSteps : 380, Gen Loss Total : 37.953, Mel-Spec. Error : 0.501, s/b : 2.360\nSteps : 385, Gen Loss Total : 38.181, Mel-Spec. Error : 0.507, s/b : 2.373\nSteps : 390, Gen Loss Total : 37.868, Mel-Spec. Error : 0.510, s/b : 2.370\nSteps : 395, Gen Loss Total : 36.901, Mel-Spec. Error : 0.486, s/b : 2.357\nTime taken for epoch 19 is 50 sec\n\nCurrent learning rate: 1.631383028780241e-05\nEpoch: 20\nSteps : 400, Gen Loss Total : 37.536, Mel-Spec. Error : 0.513, s/b : 2.457\nSteps : 405, Gen Loss Total : 36.295, Mel-Spec. Error : 0.495, s/b : 2.359\nSteps : 410, Gen Loss Total : 36.087, Mel-Spec. Error : 0.491, s/b : 2.362\nSteps : 415, Gen Loss Total : 38.569, Mel-Spec. Error : 0.511, s/b : 2.357\nSteps : 420, Gen Loss Total : 36.780, Mel-Spec. Error : 0.486, s/b : 2.360\nTime taken for epoch 20 is 50 sec\n\nCurrent learning rate: 1.5824415379168337e-05\nEpoch: 21\nSteps : 425, Gen Loss Total : 37.141, Mel-Spec. Error : 0.491, s/b : 2.382\nSteps : 430, Gen Loss Total : 37.537, Mel-Spec. Error : 0.495, s/b : 2.364\nSteps : 435, Gen Loss Total : 38.911, Mel-Spec. Error : 0.529, s/b : 2.358\nSteps : 440, Gen Loss Total : 35.248, Mel-Spec. Error : 0.465, s/b : 2.357\nTime taken for epoch 21 is 50 sec\n\nCurrent learning rate: 1.5349682917793287e-05\nEpoch: 22\nSteps : 445, Gen Loss Total : 36.875, Mel-Spec. Error : 0.492, s/b : 2.360\nSteps : 450, Gen Loss Total : 38.229, Mel-Spec. Error : 0.520, s/b : 2.370\nSteps : 455, Gen Loss Total : 36.960, Mel-Spec. Error : 0.499, s/b : 2.359\nSteps : 460, Gen Loss Total : 35.977, Mel-Spec. Error : 0.479, s/b : 2.358\nTime taken for epoch 22 is 50 sec\n\nCurrent learning rate: 1.4889192430259489e-05\nEpoch: 23\nSteps : 465, Gen Loss Total : 37.417, Mel-Spec. Error : 0.492, s/b : 2.374\nSteps : 470, Gen Loss Total : 36.028, Mel-Spec. Error : 0.490, s/b : 2.355\nSteps : 475, Gen Loss Total : 36.841, Mel-Spec. Error : 0.491, s/b : 2.368\nSteps : 480, Gen Loss Total : 36.535, Mel-Spec. Error : 0.512, s/b : 2.354\nTime taken for epoch 23 is 50 sec\n\nCurrent learning rate: 1.4442516657351704e-05\nEpoch: 24\nSteps : 485, Gen Loss Total : 37.831, Mel-Spec. Error : 0.497, s/b : 2.374\nSteps : 490, Gen Loss Total : 38.499, Mel-Spec. Error : 0.497, s/b : 2.362\nSteps : 495, Gen Loss Total : 37.633, Mel-Spec. Error : 0.494, s/b : 2.367\nSteps : 500, Gen Loss Total : 38.148, Mel-Spec. Error : 0.505, s/b : 2.360\nSaving checkpoint to /kaggle/working/hifimodels/-/g_00000000\nComplete.\nSaving checkpoint to /kaggle/working/hifimodels/-/do_00000000\nComplete.\nTime taken for epoch 24 is 53 sec\n\nCurrent learning rate: 1.4009241157631153e-05\nEpoch: 25\nSteps : 505, Gen Loss Total : 37.757, Mel-Spec. Error : 0.509, s/b : 2.457\nSteps : 510, Gen Loss Total : 39.702, Mel-Spec. Error : 0.546, s/b : 2.362\nSteps : 515, Gen Loss Total : 37.274, Mel-Spec. Error : 0.493, s/b : 2.372\nSteps : 520, Gen Loss Total : 37.442, Mel-Spec. Error : 0.502, s/b : 2.359\nSteps : 525, Gen Loss Total : 36.194, Mel-Spec. Error : 0.481, s/b : 2.354\nTime taken for epoch 25 is 50 sec\n\nCurrent learning rate: 1.3588963922902217e-05\nEpoch: 26\nSteps : 530, Gen Loss Total : 36.506, Mel-Spec. Error : 0.484, s/b : 2.399\nSteps : 535, Gen Loss Total : 37.391, Mel-Spec. Error : 0.500, s/b : 2.358\nSteps : 540, Gen Loss Total : 35.482, Mel-Spec. Error : 0.474, s/b : 2.353\nSteps : 545, Gen Loss Total : 34.988, Mel-Spec. Error : 0.467, s/b : 2.351\nTime taken for epoch 26 is 50 sec\n\nCurrent learning rate: 1.318129500521515e-05\nEpoch: 27\nSteps : 550, Gen Loss Total : 39.794, Mel-Spec. Error : 0.533, s/b : 2.363\nSteps : 555, Gen Loss Total : 37.795, Mel-Spec. Error : 0.496, s/b : 2.359\nSteps : 560, Gen Loss Total : 37.847, Mel-Spec. Error : 0.508, s/b : 2.356\nSteps : 565, Gen Loss Total : 37.835, Mel-Spec. Error : 0.498, s/b : 2.358\nTime taken for epoch 27 is 50 sec\n\nCurrent learning rate: 1.2785856155058695e-05\nEpoch: 28\nSteps : 570, Gen Loss Total : 36.377, Mel-Spec. Error : 0.487, s/b : 2.387\nSteps : 575, Gen Loss Total : 36.954, Mel-Spec. Error : 0.490, s/b : 2.373\nSteps : 580, Gen Loss Total : 36.086, Mel-Spec. Error : 0.480, s/b : 2.368\nSteps : 585, Gen Loss Total : 36.013, Mel-Spec. Error : 0.473, s/b : 2.351\nTime taken for epoch 28 is 50 sec\n\nCurrent learning rate: 1.2402280470406934e-05\nEpoch: 29\nSteps : 590, Gen Loss Total : 37.401, Mel-Spec. Error : 0.501, s/b : 2.365\nSteps : 595, Gen Loss Total : 36.651, Mel-Spec. Error : 0.497, s/b : 2.364\nSteps : 600, Gen Loss Total : 36.891, Mel-Spec. Error : 0.484, s/b : 2.367\nSteps : 605, Gen Loss Total : 36.796, Mel-Spec. Error : 0.482, s/b : 2.357\nTime taken for epoch 29 is 50 sec\n\nCurrent learning rate: 1.2030212056294726e-05\nEpoch: 30\nSteps : 610, Gen Loss Total : 37.694, Mel-Spec. Error : 0.502, s/b : 2.467\nSteps : 615, Gen Loss Total : 36.913, Mel-Spec. Error : 0.486, s/b : 2.371\nSteps : 620, Gen Loss Total : 35.971, Mel-Spec. Error : 0.480, s/b : 2.367\nSteps : 625, Gen Loss Total : 37.081, Mel-Spec. Error : 0.492, s/b : 2.351\nSteps : 630, Gen Loss Total : 36.566, Mel-Spec. Error : 0.484, s/b : 2.346\nTime taken for epoch 30 is 50 sec\n\nCurrent learning rate: 1.1669305694605884e-05\nEpoch: 31\nSteps : 635, Gen Loss Total : 37.367, Mel-Spec. Error : 0.487, s/b : 2.371\nSteps : 640, Gen Loss Total : 37.724, Mel-Spec. Error : 0.490, s/b : 2.350\nSteps : 645, Gen Loss Total : 34.816, Mel-Spec. Error : 0.459, s/b : 2.357\nSteps : 650, Gen Loss Total : 36.412, Mel-Spec. Error : 0.482, s/b : 2.357\nTime taken for epoch 31 is 50 sec\n\nCurrent learning rate: 1.1319226523767708e-05\nEpoch: 32\nSteps : 655, Gen Loss Total : 39.231, Mel-Spec. Error : 0.516, s/b : 2.362\nSteps : 660, Gen Loss Total : 37.429, Mel-Spec. Error : 0.500, s/b : 2.367\nSteps : 665, Gen Loss Total : 36.689, Mel-Spec. Error : 0.496, s/b : 2.348\nSteps : 670, Gen Loss Total : 36.260, Mel-Spec. Error : 0.485, s/b : 2.346\nTime taken for epoch 32 is 50 sec\n\nCurrent learning rate: 1.0979649728054676e-05\nEpoch: 33\nSteps : 675, Gen Loss Total : 36.022, Mel-Spec. Error : 0.477, s/b : 2.362\nSteps : 680, Gen Loss Total : 37.911, Mel-Spec. Error : 0.493, s/b : 2.357\nSteps : 685, Gen Loss Total : 35.738, Mel-Spec. Error : 0.477, s/b : 2.365\nSteps : 690, Gen Loss Total : 35.592, Mel-Spec. Error : 0.475, s/b : 2.359\nTime taken for epoch 33 is 50 sec\n\nCurrent learning rate: 1.0650260236213036e-05\nEpoch: 34\nSteps : 695, Gen Loss Total : 36.812, Mel-Spec. Error : 0.481, s/b : 2.362\nSteps : 700, Gen Loss Total : 36.594, Mel-Spec. Error : 0.480, s/b : 2.367\nSteps : 705, Gen Loss Total : 37.386, Mel-Spec. Error : 0.493, s/b : 2.371\nSteps : 710, Gen Loss Total : 36.345, Mel-Spec. Error : 0.470, s/b : 2.359\nTime taken for epoch 34 is 50 sec\n\nCurrent learning rate: 1.0330752429126645e-05\nEpoch: 35\nSteps : 715, Gen Loss Total : 36.563, Mel-Spec. Error : 0.487, s/b : 2.564\nSteps : 720, Gen Loss Total : 36.050, Mel-Spec. Error : 0.495, s/b : 2.364\nSteps : 725, Gen Loss Total : 36.170, Mel-Spec. Error : 0.501, s/b : 2.352\nSteps : 730, Gen Loss Total : 36.265, Mel-Spec. Error : 0.489, s/b : 2.356\nSteps : 735, Gen Loss Total : 35.923, Mel-Spec. Error : 0.470, s/b : 2.369\nTime taken for epoch 35 is 51 sec\n\nCurrent learning rate: 1.0020829856252845e-05\nEpoch: 36\nSteps : 740, Gen Loss Total : 35.194, Mel-Spec. Error : 0.467, s/b : 2.359\nSteps : 745, Gen Loss Total : 36.473, Mel-Spec. Error : 0.472, s/b : 2.369\nSteps : 750, Gen Loss Total : 35.480, Mel-Spec. Error : 0.465, s/b : 2.349\nSaving checkpoint to /kaggle/working/hifimodels/-/g_00000000\nComplete.\nSaving checkpoint to /kaggle/working/hifimodels/-/do_00000000\nComplete.\nSteps : 755, Gen Loss Total : 36.999, Mel-Spec. Error : 0.482, s/b : 2.351\nTime taken for epoch 36 is 53 sec\n\nCurrent learning rate: 9.720204960565259e-06\nEpoch: 37\nSteps : 760, Gen Loss Total : 37.037, Mel-Spec. Error : 0.480, s/b : 2.365\nSteps : 765, Gen Loss Total : 37.468, Mel-Spec. Error : 0.513, s/b : 2.362\nSteps : 770, Gen Loss Total : 36.662, Mel-Spec. Error : 0.498, s/b : 2.349\nSteps : 775, Gen Loss Total : 36.534, Mel-Spec. Error : 0.487, s/b : 2.376\nTime taken for epoch 37 is 50 sec\n\nCurrent learning rate: 9.4285988117483e-06\nEpoch: 38\nSteps : 780, Gen Loss Total : 37.148, Mel-Spec. Error : 0.497, s/b : 2.392\nSteps : 785, Gen Loss Total : 37.119, Mel-Spec. Error : 0.484, s/b : 2.367\nSteps : 790, Gen Loss Total : 36.121, Mel-Spec. Error : 0.479, s/b : 2.370\nSteps : 795, Gen Loss Total : 36.058, Mel-Spec. Error : 0.473, s/b : 2.349\nTime taken for epoch 38 is 50 sec\n\nCurrent learning rate: 9.14574084739585e-06\nEpoch: 39\nSteps : 800, Gen Loss Total : 37.590, Mel-Spec. Error : 0.487, s/b : 2.367\nSteps : 805, Gen Loss Total : 37.557, Mel-Spec. Error : 0.492, s/b : 2.354\nSteps : 810, Gen Loss Total : 36.891, Mel-Spec. Error : 0.483, s/b : 2.357\nSteps : 815, Gen Loss Total : 37.132, Mel-Spec. Error : 0.480, s/b : 2.358\nTime taken for epoch 39 is 50 sec\n\nCurrent learning rate: 8.871368621973974e-06\nEpoch: 40\nSteps : 820, Gen Loss Total : 36.857, Mel-Spec. Error : 0.490, s/b : 2.410\nSteps : 825, Gen Loss Total : 36.461, Mel-Spec. Error : 0.489, s/b : 2.368\nSteps : 830, Gen Loss Total : 35.385, Mel-Spec. Error : 0.482, s/b : 2.363\nSteps : 835, Gen Loss Total : 37.374, Mel-Spec. Error : 0.487, s/b : 2.350\nSteps : 840, Gen Loss Total : 35.478, Mel-Spec. Error : 0.471, s/b : 2.355\nTime taken for epoch 40 is 50 sec\n\nCurrent learning rate: 8.605227563314754e-06\nEpoch: 41\nSteps : 845, Gen Loss Total : 35.890, Mel-Spec. Error : 0.490, s/b : 2.374\nSteps : 850, Gen Loss Total : 37.027, Mel-Spec. Error : 0.483, s/b : 2.372\nSteps : 855, Gen Loss Total : 35.436, Mel-Spec. Error : 0.461, s/b : 2.359\nSteps : 860, Gen Loss Total : 35.075, Mel-Spec. Error : 0.457, s/b : 2.345\nTime taken for epoch 41 is 50 sec\n\nCurrent learning rate: 8.347070736415311e-06\nEpoch: 42\nSteps : 865, Gen Loss Total : 38.645, Mel-Spec. Error : 0.510, s/b : 2.360\nSteps : 870, Gen Loss Total : 37.071, Mel-Spec. Error : 0.490, s/b : 2.366\nSteps : 875, Gen Loss Total : 36.192, Mel-Spec. Error : 0.483, s/b : 2.360\nSteps : 880, Gen Loss Total : 36.160, Mel-Spec. Error : 0.472, s/b : 2.359\nTime taken for epoch 42 is 50 sec\n\nCurrent learning rate: 8.09665861432285e-06\nEpoch: 43\nSteps : 885, Gen Loss Total : 36.669, Mel-Spec. Error : 0.487, s/b : 2.367\nSteps : 890, Gen Loss Total : 36.958, Mel-Spec. Error : 0.484, s/b : 2.363\nSteps : 895, Gen Loss Total : 35.666, Mel-Spec. Error : 0.473, s/b : 2.365\nSteps : 900, Gen Loss Total : 35.734, Mel-Spec. Error : 0.467, s/b : 2.357\nTime taken for epoch 43 is 50 sec\n\nCurrent learning rate: 7.853758855893165e-06\nEpoch: 44\nSteps : 905, Gen Loss Total : 37.606, Mel-Spec. Error : 0.490, s/b : 2.369\nSteps : 910, Gen Loss Total : 34.455, Mel-Spec. Error : 0.456, s/b : 2.353\nSteps : 915, Gen Loss Total : 36.035, Mel-Spec. Error : 0.475, s/b : 2.372\nSteps : 920, Gen Loss Total : 35.087, Mel-Spec. Error : 0.465, s/b : 2.353\nTime taken for epoch 44 is 50 sec\n\nCurrent learning rate: 7.61814609021637e-06\nEpoch: 45\nSteps : 925, Gen Loss Total : 36.112, Mel-Spec. Error : 0.487, s/b : 2.639\nSteps : 930, Gen Loss Total : 36.741, Mel-Spec. Error : 0.491, s/b : 2.364\nSteps : 935, Gen Loss Total : 37.477, Mel-Spec. Error : 0.513, s/b : 2.366\nSteps : 940, Gen Loss Total : 36.722, Mel-Spec. Error : 0.476, s/b : 2.353\nSteps : 945, Gen Loss Total : 37.101, Mel-Spec. Error : 0.482, s/b : 2.347\nTime taken for epoch 45 is 50 sec\n\nCurrent learning rate: 7.389601707509879e-06\nEpoch: 46\nSteps : 950, Gen Loss Total : 36.176, Mel-Spec. Error : 0.475, s/b : 2.362\nSteps : 955, Gen Loss Total : 37.544, Mel-Spec. Error : 0.486, s/b : 2.365\nSteps : 960, Gen Loss Total : 36.310, Mel-Spec. Error : 0.467, s/b : 2.352\nSteps : 965, Gen Loss Total : 36.878, Mel-Spec. Error : 0.477, s/b : 2.355\nTime taken for epoch 46 is 50 sec\n\nCurrent learning rate: 7.167913656284583e-06\nEpoch: 47\nSteps : 970, Gen Loss Total : 37.663, Mel-Spec. Error : 0.497, s/b : 2.366\nSteps : 975, Gen Loss Total : 37.801, Mel-Spec. Error : 0.491, s/b : 2.357\nSteps : 980, Gen Loss Total : 37.408, Mel-Spec. Error : 0.494, s/b : 2.356\nSteps : 985, Gen Loss Total : 36.541, Mel-Spec. Error : 0.478, s/b : 2.352\nTime taken for epoch 47 is 50 sec\n\nCurrent learning rate: 6.952876246596045e-06\nEpoch: 48\nSteps : 990, Gen Loss Total : 36.701, Mel-Spec. Error : 0.479, s/b : 2.364\nSteps : 995, Gen Loss Total : 35.932, Mel-Spec. Error : 0.470, s/b : 2.370\nSteps : 1000, Gen Loss Total : 34.611, Mel-Spec. Error : 0.461, s/b : 2.364\nSaving checkpoint to /kaggle/working/hifimodels/-/g_00000000\nComplete.\nSaving checkpoint to /kaggle/working/hifimodels/-/do_00000000\nComplete.\nSteps : 1005, Gen Loss Total : 35.701, Mel-Spec. Error : 0.475, s/b : 2.361\nTime taken for epoch 48 is 53 sec\n\nCurrent learning rate: 6.744289959198163e-06\nEpoch: 49\nSteps : 1010, Gen Loss Total : 36.666, Mel-Spec. Error : 0.483, s/b : 2.366\nSteps : 1015, Gen Loss Total : 37.491, Mel-Spec. Error : 0.483, s/b : 2.361\nSteps : 1020, Gen Loss Total : 36.948, Mel-Spec. Error : 0.478, s/b : 2.357\nSteps : 1025, Gen Loss Total : 35.847, Mel-Spec. Error : 0.476, s/b : 2.366\nTime taken for epoch 49 is 50 sec\n\nCurrent learning rate: 6.541961260422218e-06\nEpoch: 50\nSteps : 1030, Gen Loss Total : 36.832, Mel-Spec. Error : 0.481, s/b : 2.711\nSteps : 1035, Gen Loss Total : 35.411, Mel-Spec. Error : 0.473, s/b : 2.371\nSteps : 1040, Gen Loss Total : 36.085, Mel-Spec. Error : 0.482, s/b : 2.362\nSteps : 1045, Gen Loss Total : 35.315, Mel-Spec. Error : 0.465, s/b : 2.356\nSteps : 1050, Gen Loss Total : 35.885, Mel-Spec. Error : 0.471, s/b : 2.354\nTime taken for epoch 50 is 50 sec\n\nCurrent learning rate: 6.345702422609551e-06\nEpoch: 51\nSteps : 1055, Gen Loss Total : 36.731, Mel-Spec. Error : 0.476, s/b : 2.355\nSteps : 1060, Gen Loss Total : 37.635, Mel-Spec. Error : 0.488, s/b : 2.361\nSteps : 1065, Gen Loss Total : 36.198, Mel-Spec. Error : 0.473, s/b : 2.354\nSteps : 1070, Gen Loss Total : 36.428, Mel-Spec. Error : 0.476, s/b : 2.362\nTime taken for epoch 51 is 50 sec\n\nCurrent learning rate: 6.155331349931264e-06\nEpoch: 52\nSteps : 1075, Gen Loss Total : 37.288, Mel-Spec. Error : 0.497, s/b : 2.364\nSteps : 1080, Gen Loss Total : 36.935, Mel-Spec. Error : 0.479, s/b : 2.364\nSteps : 1085, Gen Loss Total : 36.801, Mel-Spec. Error : 0.493, s/b : 2.350\nSteps : 1090, Gen Loss Total : 35.427, Mel-Spec. Error : 0.458, s/b : 2.361\nTime taken for epoch 52 is 50 sec\n\nCurrent learning rate: 5.970671409433326e-06\nEpoch: 53\nSteps : 1095, Gen Loss Total : 36.263, Mel-Spec. Error : 0.472, s/b : 2.357\nSteps : 1100, Gen Loss Total : 36.437, Mel-Spec. Error : 0.482, s/b : 2.364\nSteps : 1105, Gen Loss Total : 35.732, Mel-Spec. Error : 0.468, s/b : 2.360\nSteps : 1110, Gen Loss Total : 36.421, Mel-Spec. Error : 0.462, s/b : 2.353\nTime taken for epoch 53 is 50 sec\n\nCurrent learning rate: 5.7915512671503264e-06\nEpoch: 54\nSteps : 1115, Gen Loss Total : 37.021, Mel-Spec. Error : 0.475, s/b : 2.363\nSteps : 1120, Gen Loss Total : 36.364, Mel-Spec. Error : 0.470, s/b : 2.360\nSteps : 1125, Gen Loss Total : 35.704, Mel-Spec. Error : 0.464, s/b : 2.362\nSteps : 1130, Gen Loss Total : 34.347, Mel-Spec. Error : 0.448, s/b : 2.359\nTime taken for epoch 54 is 50 sec\n\nCurrent learning rate: 5.617804729135816e-06\nEpoch: 55\nSteps : 1135, Gen Loss Total : 35.848, Mel-Spec. Error : 0.482, s/b : 2.444\nSteps : 1140, Gen Loss Total : 35.758, Mel-Spec. Error : 0.468, s/b : 2.354\nSteps : 1145, Gen Loss Total : 34.724, Mel-Spec. Error : 0.467, s/b : 2.364\nSteps : 1150, Gen Loss Total : 37.990, Mel-Spec. Error : 0.500, s/b : 2.353\nSteps : 1155, Gen Loss Total : 35.145, Mel-Spec. Error : 0.462, s/b : 2.351\nTime taken for epoch 55 is 50 sec\n\nCurrent learning rate: 5.4492705872617414e-06\nEpoch: 56\nSteps : 1160, Gen Loss Total : 35.884, Mel-Spec. Error : 0.484, s/b : 2.363\nSteps : 1165, Gen Loss Total : 37.482, Mel-Spec. Error : 0.493, s/b : 2.361\nSteps : 1170, Gen Loss Total : 36.979, Mel-Spec. Error : 0.482, s/b : 2.355\nSteps : 1175, Gen Loss Total : 36.324, Mel-Spec. Error : 0.465, s/b : 2.366\nTime taken for epoch 56 is 50 sec\n\nCurrent learning rate: 5.285792469643889e-06\nEpoch: 57\nSteps : 1180, Gen Loss Total : 36.570, Mel-Spec. Error : 0.492, s/b : 2.376\nSteps : 1185, Gen Loss Total : 37.613, Mel-Spec. Error : 0.504, s/b : 2.363\nSteps : 1190, Gen Loss Total : 36.504, Mel-Spec. Error : 0.486, s/b : 2.358\nSteps : 1195, Gen Loss Total : 34.882, Mel-Spec. Error : 0.461, s/b : 2.342\nTime taken for epoch 57 is 50 sec\n\nCurrent learning rate: 5.127218695554572e-06\nEpoch: 58\nSteps : 1200, Gen Loss Total : 37.362, Mel-Spec. Error : 0.482, s/b : 2.362\nSteps : 1205, Gen Loss Total : 36.741, Mel-Spec. Error : 0.474, s/b : 2.374\nSteps : 1210, Gen Loss Total : 36.361, Mel-Spec. Error : 0.463, s/b : 2.375\nSteps : 1215, Gen Loss Total : 34.868, Mel-Spec. Error : 0.457, s/b : 2.363\nTime taken for epoch 58 is 50 sec\n\nCurrent learning rate: 4.973402134687935e-06\nEpoch: 59\nSteps : 1220, Gen Loss Total : 36.737, Mel-Spec. Error : 0.474, s/b : 2.369\nSteps : 1225, Gen Loss Total : 35.228, Mel-Spec. Error : 0.454, s/b : 2.367\nSteps : 1230, Gen Loss Total : 36.003, Mel-Spec. Error : 0.468, s/b : 2.352\nSteps : 1235, Gen Loss Total : 37.071, Mel-Spec. Error : 0.483, s/b : 2.351\nTime taken for epoch 59 is 50 sec\n\nCurrent learning rate: 4.824200070647297e-06\nEpoch: 60\nSteps : 1240, Gen Loss Total : 34.594, Mel-Spec. Error : 0.459, s/b : 2.463\nSteps : 1245, Gen Loss Total : 37.389, Mel-Spec. Error : 0.490, s/b : 2.360\nSteps : 1250, Gen Loss Total : 35.813, Mel-Spec. Error : 0.476, s/b : 2.360\nSaving checkpoint to /kaggle/working/hifimodels/-/g_00000000\nComplete.\nSaving checkpoint to /kaggle/working/hifimodels/-/do_00000000\nComplete.\nSteps : 1255, Gen Loss Total : 35.855, Mel-Spec. Error : 0.467, s/b : 2.360\nSteps : 1260, Gen Loss Total : 35.773, Mel-Spec. Error : 0.473, s/b : 2.350\nTime taken for epoch 60 is 53 sec\n\nCurrent learning rate: 4.679474068527878e-06\nEpoch: 61\nSteps : 1265, Gen Loss Total : 35.062, Mel-Spec. Error : 0.462, s/b : 2.363\nSteps : 1270, Gen Loss Total : 36.717, Mel-Spec. Error : 0.485, s/b : 2.366\nSteps : 1275, Gen Loss Total : 34.155, Mel-Spec. Error : 0.449, s/b : 2.355\nSteps : 1280, Gen Loss Total : 34.530, Mel-Spec. Error : 0.455, s/b : 2.380\nTime taken for epoch 61 is 50 sec\n\nCurrent learning rate: 4.539089846472041e-06\nEpoch: 62\nSteps : 1285, Gen Loss Total : 37.022, Mel-Spec. Error : 0.483, s/b : 2.363\nSteps : 1290, Gen Loss Total : 36.341, Mel-Spec. Error : 0.479, s/b : 2.365\nSteps : 1295, Gen Loss Total : 34.688, Mel-Spec. Error : 0.471, s/b : 2.352\nSteps : 1300, Gen Loss Total : 35.714, Mel-Spec. Error : 0.459, s/b : 2.355\nTime taken for epoch 62 is 50 sec\n\nCurrent learning rate: 4.40291715107788e-06\nEpoch: 63\nSteps : 1305, Gen Loss Total : 37.226, Mel-Spec. Error : 0.488, s/b : 2.351\nSteps : 1310, Gen Loss Total : 37.095, Mel-Spec. Error : 0.481, s/b : 2.355\nSteps : 1315, Gen Loss Total : 34.756, Mel-Spec. Error : 0.460, s/b : 2.374\nSteps : 1320, Gen Loss Total : 36.298, Mel-Spec. Error : 0.470, s/b : 2.351\nTime taken for epoch 63 is 50 sec\n\nCurrent learning rate: 4.270829636545544e-06\nEpoch: 64\nSteps : 1325, Gen Loss Total : 36.785, Mel-Spec. Error : 0.472, s/b : 2.367\nSteps : 1330, Gen Loss Total : 37.805, Mel-Spec. Error : 0.491, s/b : 2.366\nSteps : 1335, Gen Loss Total : 37.650, Mel-Spec. Error : 0.492, s/b : 2.366\nSteps : 1340, Gen Loss Total : 36.277, Mel-Spec. Error : 0.461, s/b : 2.358\nTime taken for epoch 64 is 50 sec\n\nCurrent learning rate: 4.142704747449177e-06\nEpoch: 65\nSteps : 1345, Gen Loss Total : 35.564, Mel-Spec. Error : 0.467, s/b : 2.471\nSteps : 1350, Gen Loss Total : 37.341, Mel-Spec. Error : 0.482, s/b : 2.366\nSteps : 1355, Gen Loss Total : 35.899, Mel-Spec. Error : 0.469, s/b : 2.363\nSteps : 1360, Gen Loss Total : 35.606, Mel-Spec. Error : 0.462, s/b : 2.363\nSteps : 1365, Gen Loss Total : 36.387, Mel-Spec. Error : 0.462, s/b : 2.351\nTime taken for epoch 65 is 50 sec\n\nCurrent learning rate: 4.018423605025702e-06\nEpoch: 66\nSteps : 1370, Gen Loss Total : 36.061, Mel-Spec. Error : 0.470, s/b : 2.376\nSteps : 1375, Gen Loss Total : 36.690, Mel-Spec. Error : 0.472, s/b : 2.365\nSteps : 1380, Gen Loss Total : 35.297, Mel-Spec. Error : 0.458, s/b : 2.351\nSteps : 1385, Gen Loss Total : 37.514, Mel-Spec. Error : 0.492, s/b : 2.357\nTime taken for epoch 66 is 50 sec\n\nCurrent learning rate: 3.897870896874931e-06\nEpoch: 67\nSteps : 1390, Gen Loss Total : 36.822, Mel-Spec. Error : 0.480, s/b : 2.358\nSteps : 1395, Gen Loss Total : 36.716, Mel-Spec. Error : 0.483, s/b : 2.389\nSteps : 1400, Gen Loss Total : 35.610, Mel-Spec. Error : 0.474, s/b : 2.367\nSteps : 1405, Gen Loss Total : 35.246, Mel-Spec. Error : 0.452, s/b : 2.350\nTime taken for epoch 67 is 50 sec\n\nCurrent learning rate: 3.780934769968683e-06\nEpoch: 68\nSteps : 1410, Gen Loss Total : 35.929, Mel-Spec. Error : 0.461, s/b : 2.364\nSteps : 1415, Gen Loss Total : 35.846, Mel-Spec. Error : 0.463, s/b : 2.355\nSteps : 1420, Gen Loss Total : 35.073, Mel-Spec. Error : 0.455, s/b : 2.366\nSteps : 1425, Gen Loss Total : 35.290, Mel-Spec. Error : 0.458, s/b : 2.355\nTime taken for epoch 68 is 50 sec\n\nCurrent learning rate: 3.667506726869622e-06\nEpoch: 69\nSteps : 1430, Gen Loss Total : 36.371, Mel-Spec. Error : 0.469, s/b : 2.365\nSteps : 1435, Gen Loss Total : 35.456, Mel-Spec. Error : 0.465, s/b : 2.359\nSteps : 1440, Gen Loss Total : 38.062, Mel-Spec. Error : 0.487, s/b : 2.364\nSteps : 1445, Gen Loss Total : 36.485, Mel-Spec. Error : 0.465, s/b : 2.367\nTime taken for epoch 69 is 50 sec\n\nCurrent learning rate: 3.5574815250635334e-06\nEpoch: 70\nSteps : 1450, Gen Loss Total : 38.039, Mel-Spec. Error : 0.489, s/b : 2.467\nSteps : 1455, Gen Loss Total : 36.982, Mel-Spec. Error : 0.477, s/b : 2.355\nSteps : 1460, Gen Loss Total : 34.658, Mel-Spec. Error : 0.461, s/b : 2.359\nSteps : 1465, Gen Loss Total : 35.005, Mel-Spec. Error : 0.456, s/b : 2.350\nSteps : 1470, Gen Loss Total : 35.081, Mel-Spec. Error : 0.463, s/b : 2.350\nTime taken for epoch 70 is 50 sec\n\nCurrent learning rate: 3.450757079311627e-06\nEpoch: 71\nSteps : 1475, Gen Loss Total : 36.368, Mel-Spec. Error : 0.474, s/b : 2.349\nSteps : 1480, Gen Loss Total : 36.112, Mel-Spec. Error : 0.472, s/b : 2.364\nSteps : 1485, Gen Loss Total : 35.656, Mel-Spec. Error : 0.464, s/b : 2.360\nSteps : 1490, Gen Loss Total : 36.591, Mel-Spec. Error : 0.475, s/b : 2.358\nTime taken for epoch 71 is 50 sec\n\nCurrent learning rate: 3.347234366932278e-06\nEpoch: 72\nSteps : 1495, Gen Loss Total : 35.351, Mel-Spec. Error : 0.460, s/b : 2.355\nSteps : 1500, Gen Loss Total : 36.610, Mel-Spec. Error : 0.482, s/b : 2.360\nSaving checkpoint to /kaggle/working/hifimodels/-/g_00000000\nComplete.\nSaving checkpoint to /kaggle/working/hifimodels/-/do_00000000\nComplete.\nSteps : 1505, Gen Loss Total : 36.617, Mel-Spec. Error : 0.480, s/b : 2.348\nSteps : 1510, Gen Loss Total : 36.743, Mel-Spec. Error : 0.464, s/b : 2.345\nTime taken for epoch 72 is 53 sec\n\nCurrent learning rate: 3.2468173359243097e-06\nEpoch: 73\nSteps : 1515, Gen Loss Total : 37.238, Mel-Spec. Error : 0.479, s/b : 2.365\nSteps : 1520, Gen Loss Total : 35.494, Mel-Spec. Error : 0.463, s/b : 2.364\nSteps : 1525, Gen Loss Total : 35.937, Mel-Spec. Error : 0.468, s/b : 2.357\nSteps : 1530, Gen Loss Total : 36.795, Mel-Spec. Error : 0.474, s/b : 2.355\nTime taken for epoch 73 is 50 sec\n\nCurrent learning rate: 3.1494128158465805e-06\nEpoch: 74\nSteps : 1535, Gen Loss Total : 36.225, Mel-Spec. Error : 0.468, s/b : 2.359\nSteps : 1540, Gen Loss Total : 36.327, Mel-Spec. Error : 0.473, s/b : 2.379\nSteps : 1545, Gen Loss Total : 36.733, Mel-Spec. Error : 0.478, s/b : 2.366\nSteps : 1550, Gen Loss Total : 36.293, Mel-Spec. Error : 0.464, s/b : 2.351\nTime taken for epoch 74 is 50 sec\n\nCurrent learning rate: 3.054930431371183e-06\nEpoch: 75\nSteps : 1555, Gen Loss Total : 36.110, Mel-Spec. Error : 0.473, s/b : 2.448\nSteps : 1560, Gen Loss Total : 37.137, Mel-Spec. Error : 0.484, s/b : 2.355\nSteps : 1565, Gen Loss Total : 36.160, Mel-Spec. Error : 0.480, s/b : 2.369\nSteps : 1570, Gen Loss Total : 35.376, Mel-Spec. Error : 0.461, s/b : 2.360\nSteps : 1575, Gen Loss Total : 35.864, Mel-Spec. Error : 0.467, s/b : 2.354\nTime taken for epoch 75 is 50 sec\n\nCurrent learning rate: 2.9632825184300475e-06\nEpoch: 76\nSteps : 1580, Gen Loss Total : 35.993, Mel-Spec. Error : 0.465, s/b : 2.355\nSteps : 1585, Gen Loss Total : 37.288, Mel-Spec. Error : 0.475, s/b : 2.354\nSteps : 1590, Gen Loss Total : 36.389, Mel-Spec. Error : 0.470, s/b : 2.349\nSteps : 1595, Gen Loss Total : 35.838, Mel-Spec. Error : 0.473, s/b : 2.357\nTime taken for epoch 76 is 50 sec\n\nCurrent learning rate: 2.874384042877146e-06\nEpoch: 77\nSteps : 1600, Gen Loss Total : 36.268, Mel-Spec. Error : 0.472, s/b : 2.357\nSteps : 1605, Gen Loss Total : 39.080, Mel-Spec. Error : 0.506, s/b : 2.363\nSteps : 1610, Gen Loss Total : 36.830, Mel-Spec. Error : 0.488, s/b : 2.365\nSteps : 1615, Gen Loss Total : 36.009, Mel-Spec. Error : 0.473, s/b : 2.362\nTime taken for epoch 77 is 50 sec\n\nCurrent learning rate: 2.7881525215908316e-06\nEpoch: 78\nSteps : 1620, Gen Loss Total : 37.939, Mel-Spec. Error : 0.486, s/b : 2.359\nSteps : 1625, Gen Loss Total : 35.162, Mel-Spec. Error : 0.462, s/b : 2.378\nSteps : 1630, Gen Loss Total : 36.671, Mel-Spec. Error : 0.464, s/b : 2.350\nSteps : 1635, Gen Loss Total : 35.953, Mel-Spec. Error : 0.476, s/b : 2.364\nTime taken for epoch 78 is 50 sec\n\nCurrent learning rate: 2.7045079459431064e-06\nEpoch: 79\nSteps : 1640, Gen Loss Total : 37.489, Mel-Spec. Error : 0.484, s/b : 2.355\n^C\nTraceback (most recent call last):\n  File \"train.py\", line 280, in <module>\n    main()\n  File \"train.py\", line 277, in main\n    train(0, a, h, a.warm_start)\n  File \"train.py\", line 148, in train\n    optim_d.step()\n  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py\", line 67, in wrapper\n    return wrapped(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/optim/adamw.py\", line 104, in step\n    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\nKeyboardInterrupt\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nst='/kaggle/working/tacotron2/wav/000.wav|Shut up 15 year-old'\n# /kaggle/working/tacotron2/mel/499.npy\nprint(f\"{st.split('wav')[0]}\" + \"mel\"+f\"{st.split('wav')[1]}\"+'npy')\nprint(os.path.splitext(st)[0] + '.npy')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T09:20:45.553298Z","iopub.execute_input":"2023-07-29T09:20:45.553641Z","iopub.status.idle":"2023-07-29T09:20:45.561669Z","shell.execute_reply.started":"2023-07-29T09:20:45.553609Z","shell.execute_reply":"2023-07-29T09:20:45.560907Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"/kaggle/working/tacotron2/mel/000.npy\n/kaggle/working/tacotron2/wav/000.npy\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n# 5 Zip up output folder and download (The ```g_00000000``` file is the file you'd need for synthesising)\n\nRun the code cell below to zip up your files then **ONLY** click ```Download here``` once all files have been successfully zipped up\n\n<a href=\"HiFi-GAN_Model.zip/\"> Download here </a>","metadata":{}},{"cell_type":"code","source":"!zip -r ../HiFi-GAN_Model.zip ../hifimodels/","metadata":{"execution":{"iopub.status.busy":"2023-07-29T11:25:18.500281Z","iopub.execute_input":"2023-07-29T11:25:18.500597Z","iopub.status.idle":"2023-07-29T11:26:10.043387Z","shell.execute_reply.started":"2023-07-29T11:25:18.500564Z","shell.execute_reply":"2023-07-29T11:26:10.042410Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"  adding: ../hifimodels/ (stored 0%)\n  adding: ../hifimodels/-/ (stored 0%)\n  adding: ../hifimodels/-/do_00000000 (deflated 6%)\n  adding: ../hifimodels/-/config.json (deflated 48%)\n  adding: ../hifimodels/-/g_00000000 (deflated 7%)\n  adding: ../hifimodels/-/logs/ (stored 0%)\n  adding: ../hifimodels/-/logs/events.out.tfevents.1690625910.6115fc56d6f0.1733.0 (deflated 66%)\n","output_type":"stream"}]},{"cell_type":"code","source":"!python inference.py --checkpoint_file /kaggle/working/hifimodels/-/g_00000000","metadata":{"execution":{"iopub.status.busy":"2023-07-29T11:41:34.378752Z","iopub.execute_input":"2023-07-29T11:41:34.379059Z","iopub.status.idle":"2023-07-29T11:41:54.683982Z","shell.execute_reply.started":"2023-07-29T11:41:34.379027Z","shell.execute_reply":"2023-07-29T11:41:54.682774Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Initializing Inference Process..\nLoading '/kaggle/working/hifimodels/-/g_00000000'\nComplete.\nRemoving weight norm...\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: stft will require the return_complex parameter be explicitly  specified in a future PyTorch release. Use return_complex=False  to preserve the current behavior or return_complex=True to return  a complex output. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:653.)\n  normalized, onesided, return_complex)\n/opt/conda/lib/python3.7/site-packages/torch/functional.py:516: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n  normalized, onesided, return_complex)\ngenerated_files/020_generated.wav\ngenerated_files/253_generated.wav\ngenerated_files/452_generated.wav\ngenerated_files/730_generated.wav\ngenerated_files/438_generated.wav\ngenerated_files/130_generated.wav\ngenerated_files/066_generated.wav\ngenerated_files/669_generated.wav\ngenerated_files/237_generated.wav\ngenerated_files/402_generated.wav\ngenerated_files/664_generated.wav\ngenerated_files/689_generated.wav\ngenerated_files/468_generated.wav\ngenerated_files/888_generated.wav\ngenerated_files/879_generated.wav\ngenerated_files/612_generated.wav\ngenerated_files/583_generated.wav\ngenerated_files/295_generated.wav\ngenerated_files/572_generated.wav\ngenerated_files/372_generated.wav\ngenerated_files/835_generated.wav\ngenerated_files/589_generated.wav\ngenerated_files/566_generated.wav\ngenerated_files/418_generated.wav\ngenerated_files/537_generated.wav\ngenerated_files/035_generated.wav\ngenerated_files/874_generated.wav\ngenerated_files/575_generated.wav\ngenerated_files/370_generated.wav\ngenerated_files/940_generated.wav\ngenerated_files/440_generated.wav\ngenerated_files/276_generated.wav\ngenerated_files/991_generated.wav\ngenerated_files/449_generated.wav\ngenerated_files/504_generated.wav\ngenerated_files/574_generated.wav\ngenerated_files/337_generated.wav\ngenerated_files/949_generated.wav\ngenerated_files/024_generated.wav\ngenerated_files/647_generated.wav\ngenerated_files/810_generated.wav\ngenerated_files/840_generated.wav\ngenerated_files/735_generated.wav\ngenerated_files/382_generated.wav\ngenerated_files/284_generated.wav\ngenerated_files/498_generated.wav\ngenerated_files/740_generated.wav\ngenerated_files/643_generated.wav\ngenerated_files/922_generated.wav\ngenerated_files/987_generated.wav\ngenerated_files/645_generated.wav\ngenerated_files/136_generated.wav\ngenerated_files/851_generated.wav\ngenerated_files/809_generated.wav\ngenerated_files/261_generated.wav\ngenerated_files/532_generated.wav\ngenerated_files/454_generated.wav\ngenerated_files/421_generated.wav\ngenerated_files/797_generated.wav\ngenerated_files/089_generated.wav\ngenerated_files/392_generated.wav\ngenerated_files/706_generated.wav\ngenerated_files/608_generated.wav\ngenerated_files/786_generated.wav\ngenerated_files/353_generated.wav\ngenerated_files/519_generated.wav\ngenerated_files/474_generated.wav\ngenerated_files/072_generated.wav\ngenerated_files/758_generated.wav\ngenerated_files/900_generated.wav\ngenerated_files/062_generated.wav\ngenerated_files/210_generated.wav\ngenerated_files/599_generated.wav\ngenerated_files/596_generated.wav\ngenerated_files/494_generated.wav\ngenerated_files/796_generated.wav\ngenerated_files/052_generated.wav\ngenerated_files/683_generated.wav\ngenerated_files/711_generated.wav\ngenerated_files/492_generated.wav\ngenerated_files/701_generated.wav\ngenerated_files/435_generated.wav\ngenerated_files/788_generated.wav\ngenerated_files/565_generated.wav\ngenerated_files/908_generated.wav\ngenerated_files/787_generated.wav\ngenerated_files/327_generated.wav\ngenerated_files/476_generated.wav\ngenerated_files/199_generated.wav\ngenerated_files/270_generated.wav\ngenerated_files/012_generated.wav\ngenerated_files/994_generated.wav\ngenerated_files/166_generated.wav\ngenerated_files/746_generated.wav\ngenerated_files/098_generated.wav\ngenerated_files/056_generated.wav\ngenerated_files/858_generated.wav\ngenerated_files/396_generated.wav\ngenerated_files/239_generated.wav\ngenerated_files/773_generated.wav\ngenerated_files/800_generated.wav\ngenerated_files/169_generated.wav\ngenerated_files/798_generated.wav\ngenerated_files/732_generated.wav\ngenerated_files/179_generated.wav\ngenerated_files/054_generated.wav\ngenerated_files/458_generated.wav\ngenerated_files/183_generated.wav\ngenerated_files/147_generated.wav\ngenerated_files/215_generated.wav\ngenerated_files/378_generated.wav\ngenerated_files/290_generated.wav\ngenerated_files/739_generated.wav\ngenerated_files/834_generated.wav\ngenerated_files/263_generated.wav\ngenerated_files/671_generated.wav\ngenerated_files/756_generated.wav\ngenerated_files/703_generated.wav\ngenerated_files/861_generated.wav\ngenerated_files/103_generated.wav\ngenerated_files/877_generated.wav\ngenerated_files/318_generated.wav\ngenerated_files/241_generated.wav\ngenerated_files/469_generated.wav\ngenerated_files/548_generated.wav\ngenerated_files/271_generated.wav\ngenerated_files/229_generated.wav\ngenerated_files/567_generated.wav\ngenerated_files/779_generated.wav\ngenerated_files/551_generated.wav\ngenerated_files/225_generated.wav\ngenerated_files/501_generated.wav\ngenerated_files/195_generated.wav\ngenerated_files/920_generated.wav\ngenerated_files/278_generated.wav\ngenerated_files/616_generated.wav\ngenerated_files/053_generated.wav\ngenerated_files/658_generated.wav\ngenerated_files/977_generated.wav\ngenerated_files/520_generated.wav\ngenerated_files/927_generated.wav\ngenerated_files/325_generated.wav\ngenerated_files/831_generated.wav\ngenerated_files/509_generated.wav\ngenerated_files/976_generated.wav\ngenerated_files/941_generated.wav\ngenerated_files/953_generated.wav\ngenerated_files/433_generated.wav\ngenerated_files/242_generated.wav\ngenerated_files/443_generated.wav\ngenerated_files/763_generated.wav\ngenerated_files/265_generated.wav\ngenerated_files/192_generated.wav\ngenerated_files/104_generated.wav\ngenerated_files/805_generated.wav\ngenerated_files/069_generated.wav\ngenerated_files/164_generated.wav\ngenerated_files/502_generated.wav\ngenerated_files/410_generated.wav\ngenerated_files/037_generated.wav\ngenerated_files/027_generated.wav\ngenerated_files/384_generated.wav\ngenerated_files/712_generated.wav\ngenerated_files/795_generated.wav\ngenerated_files/115_generated.wav\ngenerated_files/901_generated.wav\ngenerated_files/320_generated.wav\ngenerated_files/389_generated.wav\ngenerated_files/984_generated.wav\ngenerated_files/202_generated.wav\ngenerated_files/547_generated.wav\ngenerated_files/142_generated.wav\ngenerated_files/632_generated.wav\ngenerated_files/085_generated.wav\ngenerated_files/398_generated.wav\ngenerated_files/140_generated.wav\ngenerated_files/105_generated.wav\ngenerated_files/634_generated.wav\ngenerated_files/442_generated.wav\ngenerated_files/721_generated.wav\ngenerated_files/839_generated.wav\ngenerated_files/086_generated.wav\ngenerated_files/309_generated.wav\ngenerated_files/769_generated.wav\ngenerated_files/029_generated.wav\ngenerated_files/414_generated.wav\ngenerated_files/905_generated.wav\ngenerated_files/391_generated.wav\ngenerated_files/365_generated.wav\ngenerated_files/676_generated.wav\ngenerated_files/592_generated.wav\ngenerated_files/387_generated.wav\ngenerated_files/829_generated.wav\ngenerated_files/160_generated.wav\ngenerated_files/663_generated.wav\ngenerated_files/048_generated.wav\ngenerated_files/007_generated.wav\ngenerated_files/998_generated.wav\ngenerated_files/246_generated.wav\ngenerated_files/355_generated.wav\ngenerated_files/010_generated.wav\ngenerated_files/917_generated.wav\ngenerated_files/964_generated.wav\ngenerated_files/523_generated.wav\ngenerated_files/893_generated.wav\ngenerated_files/744_generated.wav\ngenerated_files/177_generated.wav\ngenerated_files/176_generated.wav\ngenerated_files/674_generated.wav\ngenerated_files/542_generated.wav\ngenerated_files/163_generated.wav\ngenerated_files/300_generated.wav\ngenerated_files/560_generated.wav\ngenerated_files/864_generated.wav\ngenerated_files/255_generated.wav\ngenerated_files/154_generated.wav\ngenerated_files/648_generated.wav\ngenerated_files/178_generated.wav\ngenerated_files/543_generated.wav\ngenerated_files/175_generated.wav\ngenerated_files/486_generated.wav\ngenerated_files/422_generated.wav\ngenerated_files/015_generated.wav\ngenerated_files/969_generated.wav\ngenerated_files/967_generated.wav\ngenerated_files/326_generated.wav\ngenerated_files/717_generated.wav\ngenerated_files/882_generated.wav\ngenerated_files/956_generated.wav\ngenerated_files/736_generated.wav\ngenerated_files/445_generated.wav\ngenerated_files/077_generated.wav\ngenerated_files/403_generated.wav\ngenerated_files/629_generated.wav\ngenerated_files/544_generated.wav\ngenerated_files/878_generated.wav\ngenerated_files/955_generated.wav\ngenerated_files/074_generated.wav\ngenerated_files/423_generated.wav\ngenerated_files/306_generated.wav\ngenerated_files/406_generated.wav\ngenerated_files/855_generated.wav\ngenerated_files/902_generated.wav\ngenerated_files/678_generated.wav\ngenerated_files/393_generated.wav\ngenerated_files/094_generated.wav\ngenerated_files/405_generated.wav\ngenerated_files/245_generated.wav\n^C\nTraceback (most recent call last):\n  File \"inference.py\", line 94, in <module>\n    main()\n  File \"inference.py\", line 90, in main\n    inference(a)\n  File \"inference.py\", line 55, in inference\n    y_g_hat = generator(x)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/kaggle/working/hifi-gan/models.py\", line 108, in forward\n    xs = self.resblocks[i*self.num_kernels+j](x)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/kaggle/working/hifi-gan/models.py\", line 38, in forward\n    xt = c1(xt)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 259, in forward\n    self.padding, self.dilation, self.groups)\nKeyboardInterrupt\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2023-07-29T11:38:54.180536Z","iopub.execute_input":"2023-07-29T11:38:54.180835Z","iopub.status.idle":"2023-07-29T11:38:54.186971Z","shell.execute_reply.started":"2023-07-29T11:38:54.180805Z","shell.execute_reply":"2023-07-29T11:38:54.186203Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/hifi-gan'"},"metadata":{}}]},{"cell_type":"code","source":"mkdir test_files","metadata":{"execution":{"iopub.status.busy":"2023-07-29T11:38:55.439271Z","iopub.execute_input":"2023-07-29T11:38:55.440049Z","iopub.status.idle":"2023-07-29T11:38:56.390408Z","shell.execute_reply.started":"2023-07-29T11:38:55.440011Z","shell.execute_reply":"2023-07-29T11:38:56.389295Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"os.system(f'cp -a /kaggle/working/tacotron2/wav /kaggle/working/hifi-gan')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T11:40:19.090911Z","iopub.execute_input":"2023-07-29T11:40:19.091240Z","iopub.status.idle":"2023-07-29T11:40:19.305057Z","shell.execute_reply.started":"2023-07-29T11:40:19.091204Z","shell.execute_reply":"2023-07-29T11:40:19.304230Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"os.rename(f'/kaggle/working/hifi-gan/wav', f'/kaggle/working/hifi-gan/test_files')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T11:41:13.129660Z","iopub.execute_input":"2023-07-29T11:41:13.129983Z","iopub.status.idle":"2023-07-29T11:41:13.135051Z","shell.execute_reply.started":"2023-07-29T11:41:13.129948Z","shell.execute_reply":"2023-07-29T11:41:13.134043Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"os.rmdir(f'/kaggle/working/hifi-gan/test_mel_files')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:32:29.077526Z","iopub.execute_input":"2023-07-29T12:32:29.077853Z","iopub.status.idle":"2023-07-29T12:32:29.082849Z","shell.execute_reply.started":"2023-07-29T12:32:29.077816Z","shell.execute_reply":"2023-07-29T12:32:29.082019Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"os.system(f'cp -a /kaggle/working/tacotron2/mel /kaggle/working/hifi-gan')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:32:34.909153Z","iopub.execute_input":"2023-07-29T12:32:34.909781Z","iopub.status.idle":"2023-07-29T12:32:35.155825Z","shell.execute_reply.started":"2023-07-29T12:32:34.909743Z","shell.execute_reply":"2023-07-29T12:32:35.154952Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"os.rename(f'/kaggle/working/hifi-gan/mel', f'/kaggle/working/hifi-gan/test_mel_files')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:33:33.303870Z","iopub.execute_input":"2023-07-29T12:33:33.304214Z","iopub.status.idle":"2023-07-29T12:33:33.310847Z","shell.execute_reply.started":"2023-07-29T12:33:33.304177Z","shell.execute_reply":"2023-07-29T12:33:33.308757Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"shutil.rmtree(f'/kaggle/working/hifi-gan/generated_files')","metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:36:26.044199Z","iopub.execute_input":"2023-07-29T12:36:26.045009Z","iopub.status.idle":"2023-07-29T12:36:26.066986Z","shell.execute_reply.started":"2023-07-29T12:36:26.044970Z","shell.execute_reply":"2023-07-29T12:36:26.066088Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"!python inference_e2e.py --checkpoint_file /kaggle/working/hifimodels/-/g_00000000","metadata":{"execution":{"iopub.status.busy":"2023-07-29T12:36:30.189826Z","iopub.execute_input":"2023-07-29T12:36:30.190123Z","iopub.status.idle":"2023-07-29T12:36:42.022788Z","shell.execute_reply.started":"2023-07-29T12:36:30.190092Z","shell.execute_reply":"2023-07-29T12:36:42.021847Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Initializing Inference Process..\nLoading '/kaggle/working/hifimodels/-/g_00000000'\nComplete.\nRemoving weight norm...\ngenerated_files_from_mel/354.wav\ngenerated_files_from_mel/909.wav\ngenerated_files_from_mel/197.wav\ngenerated_files_from_mel/005.wav\ngenerated_files_from_mel/139.wav\ngenerated_files_from_mel/343.wav\ngenerated_files_from_mel/549.wav\ngenerated_files_from_mel/948.wav\ngenerated_files_from_mel/892.wav\ngenerated_files_from_mel/910.wav\ngenerated_files_from_mel/902.wav\ngenerated_files_from_mel/629.wav\ngenerated_files_from_mel/022.wav\ngenerated_files_from_mel/278.wav\ngenerated_files_from_mel/989.wav\ngenerated_files_from_mel/923.wav\ngenerated_files_from_mel/793.wav\ngenerated_files_from_mel/357.wav\ngenerated_files_from_mel/322.wav\ngenerated_files_from_mel/054.wav\ngenerated_files_from_mel/952.wav\ngenerated_files_from_mel/920.wav\ngenerated_files_from_mel/560.wav\ngenerated_files_from_mel/439.wav\ngenerated_files_from_mel/308.wav\ngenerated_files_from_mel/445.wav\ngenerated_files_from_mel/112.wav\ngenerated_files_from_mel/063.wav\ngenerated_files_from_mel/577.wav\ngenerated_files_from_mel/342.wav\ngenerated_files_from_mel/489.wav\ngenerated_files_from_mel/820.wav\ngenerated_files_from_mel/455.wav\ngenerated_files_from_mel/804.wav\ngenerated_files_from_mel/048.wav\ngenerated_files_from_mel/683.wav\ngenerated_files_from_mel/394.wav\ngenerated_files_from_mel/643.wav\ngenerated_files_from_mel/837.wav\ngenerated_files_from_mel/059.wav\ngenerated_files_from_mel/186.wav\ngenerated_files_from_mel/300.wav\ngenerated_files_from_mel/203.wav\ngenerated_files_from_mel/993.wav\ngenerated_files_from_mel/358.wav\ngenerated_files_from_mel/153.wav\ngenerated_files_from_mel/491.wav\ngenerated_files_from_mel/525.wav\ngenerated_files_from_mel/173.wav\ngenerated_files_from_mel/817.wav\ngenerated_files_from_mel/703.wav\ngenerated_files_from_mel/428.wav\ngenerated_files_from_mel/776.wav\ngenerated_files_from_mel/465.wav\ngenerated_files_from_mel/705.wav\ngenerated_files_from_mel/533.wav\ngenerated_files_from_mel/334.wav\ngenerated_files_from_mel/873.wav\ngenerated_files_from_mel/004.wav\ngenerated_files_from_mel/786.wav\ngenerated_files_from_mel/995.wav\ngenerated_files_from_mel/937.wav\ngenerated_files_from_mel/032.wav\ngenerated_files_from_mel/199.wav\ngenerated_files_from_mel/935.wav\ngenerated_files_from_mel/261.wav\ngenerated_files_from_mel/898.wav\ngenerated_files_from_mel/982.wav\ngenerated_files_from_mel/430.wav\ngenerated_files_from_mel/765.wav\ngenerated_files_from_mel/332.wav\ngenerated_files_from_mel/621.wav\ngenerated_files_from_mel/594.wav\ngenerated_files_from_mel/207.wav\ngenerated_files_from_mel/335.wav\ngenerated_files_from_mel/990.wav\ngenerated_files_from_mel/749.wav\ngenerated_files_from_mel/034.wav\ngenerated_files_from_mel/036.wav\ngenerated_files_from_mel/515.wav\ngenerated_files_from_mel/788.wav\ngenerated_files_from_mel/631.wav\ngenerated_files_from_mel/574.wav\ngenerated_files_from_mel/591.wav\ngenerated_files_from_mel/448.wav\ngenerated_files_from_mel/999.wav\ngenerated_files_from_mel/540.wav\ngenerated_files_from_mel/864.wav\ngenerated_files_from_mel/277.wav\ngenerated_files_from_mel/763.wav\ngenerated_files_from_mel/047.wav\ngenerated_files_from_mel/254.wav\ngenerated_files_from_mel/660.wav\ngenerated_files_from_mel/136.wav\ngenerated_files_from_mel/502.wav\ngenerated_files_from_mel/021.wav\ngenerated_files_from_mel/031.wav\ngenerated_files_from_mel/704.wav\ngenerated_files_from_mel/251.wav\ngenerated_files_from_mel/097.wav\ngenerated_files_from_mel/090.wav\ngenerated_files_from_mel/029.wav\n^C\nTraceback (most recent call last):\n  File \"inference_e2e.py\", line 93, in <module>\n    main()\n  File \"inference_e2e.py\", line 89, in main\n    inference(a)\n  File \"inference_e2e.py\", line 55, in inference\n    audio = audio.cpu().numpy().astype(\"int16\")\nKeyboardInterrupt\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}